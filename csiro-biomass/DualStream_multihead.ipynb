{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-30T08:07:14.763074Z",
     "iopub.status.busy": "2025-10-30T08:07:14.762816Z",
     "iopub.status.idle": "2025-10-30T08:07:21.990822Z",
     "shell.execute_reply": "2025-10-30T08:07:21.990102Z",
     "shell.execute_reply.started": "2025-10-30T08:07:14.763052Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\conda\\envs\\kaggle\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä½¿ç”¨è®¾å¤‡: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import socket\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import timm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# ğŸ“¦ å¯¼å…¥ä¾èµ–\n",
    "# =========================================\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# âš™ï¸ 0ï¸âƒ£ å…¨å±€å‚æ•°é…ç½®\n",
    "# =========================================\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.models import get_model_weights\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"âœ… ä½¿ç”¨è®¾å¤‡: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T08:07:21.992327Z",
     "iopub.status.busy": "2025-10-30T08:07:21.991922Z",
     "iopub.status.idle": "2025-10-30T08:07:21.998124Z",
     "shell.execute_reply": "2025-10-30T08:07:21.997471Z",
     "shell.execute_reply.started": "2025-10-30T08:07:21.992307Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è·¯å¾„å·²åˆ›å»ºï¼š\n",
      "\n",
      "dir          : D:\\DATA_hao\\Kaggle_\\csiro-biomass\n",
      "train        : D:\\DATA_hao\\Kaggle_\\csiro-biomass\\train\n",
      "test         : D:\\DATA_hao\\Kaggle_\\csiro-biomass\\test\n",
      "model        : D:\\DATA_hao\\Kaggle_\\csiro-biomass\\DualStream_multihead\n",
      "data         : D:\\DATA_hao\\Kaggle_\\csiro-biomass\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–\n",
    "if socket.gethostname() == 'hao-2':\n",
    "    dir = Path('D:/DATA_hao/Kaggle_/csiro-biomass/')\n",
    "    DIRS = {\n",
    "    \"dir\":        dir,                                       \n",
    "    \"train\":     Path(dir, \"train\"),                              \n",
    "    \"test\":     Path(dir, \"test\"),                              \n",
    "    \"model\":     Path(dir,\"DualStream_multihead\"),              \n",
    "    \"data\":     Path(dir),   \n",
    "    }\n",
    "else:\n",
    "    dir = Path('/kaggle/input/csiro-biomass')\n",
    "    DIRS = {\n",
    "    \"dir\":        dir,                                       \n",
    "    \"train\":     Path(dir, \"train\"),                              \n",
    "    \"test\":     Path(dir, \"test\"),                              \n",
    "    \"model\":     Path('/kaggle/input', \"dualstream-multihead-model\"),              \n",
    "    \"data\":     Path(\"/kaggle/working/\"),   \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # è‡ªåŠ¨åˆ›å»ºç›®å½•\n",
    "# for key, path in DIRS.items():\n",
    "#     os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# æ‰“å°æ—¶ä¸€è¡Œä¸€ä¸ªåœ°å€\n",
    "print(\"âœ… è·¯å¾„å·²åˆ›å»ºï¼š\\n\")\n",
    "for key, path in DIRS.items():\n",
    "    print(f\"{key:<12} : {path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T08:07:21.999218Z",
     "iopub.status.busy": "2025-10-30T08:07:21.998874Z",
     "iopub.status.idle": "2025-10-30T08:07:22.506492Z",
     "shell.execute_reply": "2025-10-30T08:07:22.505864Z",
     "shell.execute_reply.started": "2025-10-30T08:07:21.999195Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# å°å‡½æ•°\n",
    "def show_df_info(df, name: str):\n",
    "    \"\"\"\n",
    "    æ‰“å°å•ä¸ª DataFrame çš„å½¢çŠ¶ä¸åˆ—åä¿¡æ¯ã€‚\n",
    "    å‚æ•°:\n",
    "        df   : pandas.DataFrame\n",
    "        name : æ˜¾ç¤ºåç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ“Š {name:<16} shape: {str(df.shape):<16}  åˆ—å: {df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "\n",
    "def move_column_first(df, col_name):\n",
    "    \"\"\"\n",
    "    å°† DataFrame ä¸­æŒ‡å®šåˆ—ç§»åŠ¨åˆ°æœ€å‰é¢ã€‚\n",
    "    å‚æ•°:\n",
    "        df (pd.DataFrame): åŸå§‹æ•°æ®æ¡†\n",
    "        col_name (str): è¦ç§»åŠ¨åˆ°æœ€å‰é¢çš„åˆ—å\n",
    "    è¿”å›:\n",
    "        pd.DataFrame: è°ƒæ•´åçš„æ–° DataFrame\n",
    "    \"\"\"\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError(f\"åˆ— '{col_name}' ä¸å­˜åœ¨äº DataFrame ä¸­ã€‚\")\n",
    "\n",
    "    cols = [col_name] + [c for c in df.columns if c != col_name]\n",
    "    return df[cols]\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def weighted_r2(y_true_df, y_pred_df):\n",
    "    weights = {\n",
    "        \"Dry_Green_g\": 0.1,\n",
    "        \"Dry_Dead_g\": 0.1,\n",
    "        \"Dry_Clover_g\": 0.1,\n",
    "        \"GDM_g\": 0.2,\n",
    "        \"Dry_Total_g\": 0.5\n",
    "    }\n",
    "\n",
    "    r2_dict = {}\n",
    "    for col in weights.keys():\n",
    "        r2_dict[col] = r2_score(y_true_df[col], y_pred_df[col])\n",
    "\n",
    "    weighted_score = sum(r2_dict[k] * w for k, w in weights.items())\n",
    "    return weighted_score, r2_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“˜ æ•°æ®è¯»å–ä¸é¢„å¤„ç†\n",
    "\n",
    "# 1ï¸âƒ£ è¯»å–åŸå§‹æ•°æ®\n",
    "df_file_path = Path(DIRS[\"dir\"] / \"train.csv\")\n",
    "df = pd.read_csv(df_file_path)\n",
    "show_df_info(df, \"train.csv\")\n",
    "\n",
    "# 2ï¸âƒ£ æå–å”¯ä¸€ IDï¼ˆä¾‹å¦‚ \"ID1011485656__Dry_Green_g\" â†’ \"ID1011485656\"ï¼‰\n",
    "df[\"ID\"] = df[\"sample_id\"].str.split(\"__\").str[0]\n",
    "\n",
    "# 3ï¸âƒ£ å°† ID åˆ—ç§»åŠ¨åˆ°æœ€å‰é¢\n",
    "df = move_column_first(df, \"ID\")\n",
    "show_df_info(df, \"df\")\n",
    "\n",
    "# ğŸ§© ç›®æ ‡å€¼é€è§†ï¼ˆè¡Œè½¬åˆ—ï¼‰\n",
    "df_targets = (\n",
    "    df\n",
    "    .pivot_table(\n",
    "        index=\"ID\",\n",
    "        columns=\"target_name\",\n",
    "        values=\"target\",\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "df_targets.columns.name = None  # å»æ‰å¤šçº§åˆ—åå±‚æ¬¡\n",
    "show_df_info(df_targets, \"df_targets\")\n",
    "\n",
    "# ğŸ§¬ æå–å…ƒä¿¡æ¯ï¼ˆæ¯ä¸ª ID ä»…ä¿ç•™ä¸€è¡Œï¼‰\n",
    "meta_cols = [\n",
    "    \"ID\", \"image_path\", \"Sampling_Date\", \"State\",\n",
    "    \"Species\", \"Pre_GSHH_NDVI\", \"Height_Ave_cm\"\n",
    "]\n",
    "df_meta = df[meta_cols].drop_duplicates(subset=\"ID\")\n",
    "show_df_info(df_meta, \"df_meta\")\n",
    "\n",
    "# ğŸ”— åˆå¹¶å…ƒä¿¡æ¯ä¸ç›®æ ‡æ•°æ®\n",
    "df_train = pd.merge(df_meta, df_targets, on=\"ID\", how=\"left\")\n",
    "\n",
    "show_df_info(df_train, \"df_train\")\n",
    "\n",
    "\n",
    "# df_wide.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§  MyDualStreamModelï¼šåŒæµ + å¤šå¤´å›å½’ + å†…éƒ¨è®­ç»ƒé€»è¾‘\n",
    "\n",
    "\n",
    "class WeightedSmoothL1Loss(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super().__init__()\n",
    "        self.weights = list(weights.values())\n",
    "        self.loss_fn = nn.SmoothL1Loss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        losses = self.loss_fn(pred, target)\n",
    "        weighted = sum(losses[:, i] * w for i, w in enumerate(self.weights))\n",
    "        return weighted.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MyDualStreamModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                backbone_name=\"convnext_tiny\", \n",
    "                pretrained=True, \n",
    "                freeze_ratio=0.8,\n",
    "                weights_dict=None):\n",
    "        \"\"\"\n",
    "        å‚æ•°:\n",
    "        - backbone_name: timm æ¨¡å‹åç§° (å¦‚ convnext_tiny, resnet50)\n",
    "        - pretrained: æ˜¯å¦åŠ è½½ ImageNet æƒé‡\n",
    "        - freeze_ratio: å†»ç»“æ¯”ä¾‹ï¼ˆ0~1ï¼‰\n",
    "        - weights_dict: å„ç›®æ ‡æƒé‡ (dict), ç”¨äº WeightedSmoothL1Loss\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 1ï¸âƒ£ Backbone\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0)\n",
    "        in_dim = self.backbone.num_features\n",
    "\n",
    "        # 2ï¸âƒ£ å†»ç»“éƒ¨åˆ†å‚æ•°\n",
    "        params = list(self.backbone.parameters())\n",
    "        freeze_until = int(len(params) * freeze_ratio)\n",
    "        for i, p in enumerate(params):\n",
    "            p.requires_grad = i >= freeze_until  # å‰éƒ¨åˆ†å†»ç»“ï¼Œåéƒ¨åˆ†å¯å­¦ä¹ \n",
    "\n",
    "        # 3ï¸âƒ£ åŒæµèåˆ\n",
    "        self.fusion_dim = in_dim * 2\n",
    "\n",
    "        # 4ï¸âƒ£ ä¸‰ä¸ªè¾“å‡º Head\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.fusion_dim, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 1)\n",
    "            )\n",
    "\n",
    "        self.head_total = make_head()\n",
    "        self.head_gdm   = make_head()\n",
    "        self.head_green = make_head()\n",
    "\n",
    "        # 5ï¸âƒ£ æŸå¤±å‡½æ•°ï¼ˆWeighted SmoothL1Lossï¼‰\n",
    "        self.loss_fn = WeightedSmoothL1Loss(weights_dict) if weights_dict else nn.SmoothL1Loss()\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ğŸ” Forward\n",
    "    # ------------------------------------------------------------\n",
    "    def forward(self, img_left, img_right):\n",
    "        feat_left  = self.backbone(img_left)\n",
    "        feat_right = self.backbone(img_right)\n",
    "        fused = torch.cat([feat_left, feat_right], dim=1)\n",
    "\n",
    "        total = self.head_total(fused)\n",
    "        gdm   = self.head_gdm(fused)\n",
    "        green = self.head_green(fused)\n",
    "        preds = torch.cat([green, gdm, total], dim=1)\n",
    "        return preds  # shape: [batch, 3]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ğŸ§® æŸå¤±è®¡ç®—ï¼ˆå†…éƒ¨è°ƒç”¨ï¼‰\n",
    "    # ------------------------------------------------------------\n",
    "    def compute_loss(self, preds, targets):\n",
    "        return self.loss_fn(preds, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DualStreamDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, target_cols=None, transform=None):\n",
    "        \"\"\"\n",
    "        df: DataFrameï¼ŒåŒ…å« image_path åˆ—\n",
    "        image_dir: å›¾åƒç›®å½•\n",
    "        target_cols: å¦‚æœæ˜¯è®­ç»ƒé›†ï¼ŒæŒ‡å®šç›®æ ‡åˆ—\n",
    "        transform: Albumentations å˜æ¢\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.target_cols = target_cols\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = Path(self.image_dir, str(row[\"image_path\"]))\n",
    "        \n",
    "        # ====== 1ï¸âƒ£ å®‰å…¨åŠ è½½ ======\n",
    "        if not img_path.exists():\n",
    "            print(f\"âš ï¸ å›¾ç‰‡ä¸å­˜åœ¨: {img_path}\")\n",
    "            image = np.zeros((1000, 2000, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            try:\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡: {img_path} ({e})\")\n",
    "                image = np.zeros((1000, 2000, 3), dtype=np.uint8)\n",
    "\n",
    "        # ====== 2ï¸âƒ£ ç¡®ä¿è½¬æ¢ä¸º NumPy æ•°ç»„ ======\n",
    "        image = np.array(image)  # è½¬æ¢ä¸º NumPy æ•°ç»„\n",
    "        h, w, _ = image.shape\n",
    "        mid = w // 2\n",
    "        \n",
    "        # æ‹†åˆ†æˆå·¦å³ä¸¤ä¸ª patch\n",
    "        img_left = image[:, :mid]\n",
    "        img_right = image[:, mid:]\n",
    "\n",
    "        # ====== 4ï¸âƒ£ åº”ç”¨ Albumentations å˜æ¢ ======\n",
    "        if self.transform:\n",
    "            img_left = self.transform(image=img_left)[\"image\"]\n",
    "            img_right = self.transform(image=img_right)[\"image\"]\n",
    "\n",
    "        # ====== 5ï¸âƒ£ è¿”å›ç»“æœ ======\n",
    "        if self.target_cols is not None:\n",
    "            targets = torch.tensor(row[self.target_cols].astype(float).values, dtype=torch.float32)\n",
    "            return img_left, img_right, targets\n",
    "        else:\n",
    "            return img_left, img_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ Albumentations å˜æ¢\n",
    "def get_train_transforms(size=768):\n",
    "    return A.Compose([\n",
    "        A.Resize(size, size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ColorJitter(p=0.3),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(size=768):\n",
    "    return A.Compose([\n",
    "        A.Resize(size, size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "\n",
    "def train_with_groupkfold(\n",
    "    df_train,\n",
    "    save_dir,\n",
    "    model_target_cols,\n",
    "    get_train_transforms,\n",
    "    get_valid_transforms,\n",
    "    weights,\n",
    "    freeze_ratio=0.8,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    lr=1e-4,\n",
    "    device=None,\n",
    "    n_splits=5,\n",
    "):\n",
    "\n",
    "    scaler = GradScaler()  # âœ… åˆå§‹åŒ–ç¼©æ”¾å™¨ï¼ˆç”¨äºFP16æ¢¯åº¦ç¨³å®šï¼‰\n",
    "\n",
    "    # å®šä¹‰åˆ†å±‚å™¨ï¼ˆ5æŠ˜äº¤å‰éªŒè¯ï¼‰\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    # å–ç¬¬ä¸€æŠ˜\n",
    "    df = df_train.copy()\n",
    "    groups = df[\"Sampling_Date\"]\n",
    "\n",
    "    # ğŸ”¹ ç”¨äºä¿å­˜æ¯æŠ˜è®­ç»ƒ/éªŒè¯æŸå¤±\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups=groups)):\n",
    "        print(f\"Fold {fold:3d}: Train={len(train_idx)}, Valid={len(val_idx)}\")\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        valid_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "            \n",
    "        train_dataset = DualStreamDataset(\n",
    "            train_df, DIRS[\"dir\"], model_target_cols, transform=get_train_transforms(768)\n",
    "        )\n",
    "        valid_dataset = DualStreamDataset(\n",
    "            valid_df, DIRS[\"dir\"], model_target_cols, transform=get_valid_transforms(768)\n",
    "        )\n",
    "\n",
    "        # âœ… å¢åŠ  pin_memory æé«˜ä¸»æœºâ†’GPU ä¼ è¾“é€Ÿåº¦\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "        # âœ… æ¨¡å‹ä¼˜åŒ–ï¼šchannels_last å†…å­˜å¸ƒå±€ + AMP å…¼å®¹\n",
    "        model = MyDualStreamModel(\"convnext_tiny\", pretrained=True, freeze_ratio=freeze_ratio, weights_dict=weights)\n",
    "        model = model.to(device)\n",
    "        model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "        # ğŸ”¹ æ¯æŠ˜è®°å½•æŸå¤±\n",
    "        train_losses_per_epoch = []\n",
    "        val_losses_per_epoch = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # === ğŸ”¥ å¯ç”¨æ··åˆç²¾åº¦ ===\n",
    "            model.train()\n",
    "            running_train_loss = []\n",
    "\n",
    "            # âœ… tqdm å®æ—¶æ˜¾ç¤º\n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1:3d}/{epochs}\"):\n",
    "                img_left, img_right, targets = batch\n",
    "                img_left, img_right, targets = (\n",
    "                    img_left.to(device, non_blocking=True),\n",
    "                    img_right.to(device, non_blocking=True),\n",
    "                    targets.to(device, non_blocking=True),\n",
    "                )\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)  # âœ… æ›´é«˜æ•ˆæ¸…ç©ºæ¢¯åº¦\n",
    "\n",
    "                # âœ… AMPæ··åˆç²¾åº¦ä¸Šä¸‹æ–‡\n",
    "                with autocast():\n",
    "                    preds = model(img_left, img_right)\n",
    "                    loss = model.compute_loss(preds, targets)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                # scaler.unscale_(optimizer)  # å¯é€‰ï¼šå¦‚æœæƒ³åŠ æ¢¯åº¦è£å‰ªï¼Œå¯åœ¨æ­¤è§£ç¼©æ”¾\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                running_train_loss.append(loss.item())\n",
    "\n",
    "            avg_train_loss = float(np.mean(running_train_loss))\n",
    "\n",
    "            # === ğŸ§Š éªŒè¯é˜¶æ®µï¼ˆä¸ç”¨ AMPï¼‰===\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            with torch.no_grad():\n",
    "                for batch in valid_loader:\n",
    "                    img_left, img_right, targets = batch\n",
    "                    img_left, img_right, targets = (\n",
    "                        img_left.to(device, non_blocking=True),\n",
    "                        img_right.to(device, non_blocking=True),\n",
    "                        targets.to(device, non_blocking=True),\n",
    "                    )\n",
    "                    preds = model(img_left, img_right)\n",
    "                    val_loss = model.compute_loss(preds, targets).item()\n",
    "                    val_losses.append(val_loss)\n",
    "\n",
    "            avg_val_loss = float(np.mean(val_losses))\n",
    "\n",
    "            print(f\"Epoch {epoch+1:3d} | Train={avg_train_loss:.4f} | Val={avg_val_loss:.4f}\")\n",
    "\n",
    "            train_losses_per_epoch.append(avg_train_loss)\n",
    "            val_losses_per_epoch.append(avg_val_loss)\n",
    "\n",
    "        # âœ… ä¿å­˜æ¯æŠ˜çš„æ‰€æœ‰epochæŸå¤±\n",
    "        fold_train_losses.append(train_losses_per_epoch)\n",
    "        fold_val_losses.append(val_losses_per_epoch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        save_path = save_dir / f\"model_weights_fold_{fold}.pt\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "        print(f\"âœ… å®Œæ•´æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}\")\n",
    "        \n",
    "\n",
    "    # è·å–æœ€å¤§epochæ•°ï¼ˆæœ‰æ—¶ä¸åŒfoldå¯èƒ½é•¿åº¦ä¸åŒï¼‰\n",
    "    max_epochs = max(len(x) for x in fold_train_losses)\n",
    "    df = pd.DataFrame({\"Epoch\": range(1, max_epochs + 1)})\n",
    "\n",
    "    # é€ä¸ªfoldå¡«å……\n",
    "    for i, (train_list, val_list) in enumerate(zip(fold_train_losses, fold_val_losses), start=1):\n",
    "        # è‹¥æŸä¸ªfoldé•¿åº¦ä¸è¶³ï¼Œåˆ™ç”¨Noneå¡«å……\n",
    "        pad_train = train_list + [None] * (max_epochs - len(train_list))\n",
    "        pad_val = val_list + [None] * (max_epochs - len(val_list))\n",
    "        \n",
    "        df[f\"Train_Loss_Fold{i}\"] = pad_train\n",
    "        df[f\"Val_Loss_Fold{i}\"] = pad_val\n",
    "\n",
    "    # ä¿å­˜åˆ°Excel\n",
    "    output_path = Path(save_dir, \"fold_losses_wide.xlsx\")\n",
    "    df.to_excel(output_path, index=False)\n",
    "    print(f\"âœ… æ¯Foldçš„Train/Val Losså·²ä¿å­˜ä¸ºåˆ—ï¼š{output_path}\")\n",
    "\n",
    "    return fold_train_losses, fold_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights           = {\n",
    "    \"Dry_Green_g\": 0.1,\n",
    "    \"GDM_g\":        0.2,\n",
    "    \"Dry_Total_g\":  0.5\n",
    "}\n",
    "\n",
    "model_target_cols = [\"Dry_Green_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "target_cols       = [\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"epochs\" : 2,\n",
    "    \"freeze_ratio\" : 0.8,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 1e-4,\n",
    "}\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# ğŸš€ å¯åŠ¨è®­ç»ƒï¼ˆGroupKFoldï¼‰\n",
    "# ==========================\n",
    "\n",
    "\n",
    "\n",
    "if socket.gethostname() == 'hao-2':\n",
    "\n",
    "\n",
    "    time_str = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    history_DIR = Path(DIRS['model'], time_str)\n",
    "    os.makedirs(history_DIR, exist_ok=True)\n",
    "\n",
    "    fold_train_losses, fold_val_losses = train_with_groupkfold(\n",
    "        df_train             = df_train,\n",
    "        save_dir             = history_DIR,\n",
    "        model_target_cols    = model_target_cols,\n",
    "        get_train_transforms = get_train_transforms,\n",
    "        get_valid_transforms = get_valid_transforms,\n",
    "        weights              = weights,\n",
    "        freeze_ratio         = config[\"freeze_ratio\"],\n",
    "        batch_size           = config[\"batch_size\"],\n",
    "        epochs               = config[\"epochs\"],\n",
    "        lr                   = config[\"lr\"],\n",
    "        device               = device,\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§® åå¤„ç†å‡½æ•°ï¼ˆæ¢å¤ 5 ä¸ªç›®æ ‡ï¼‰\n",
    "def recover_all_targets(df_pred_3):\n",
    "    df = df_pred_3.copy()\n",
    "    df[\"Dry_Clover_g\"] = np.maximum(0, df[\"GDM_g\"] - df[\"Dry_Green_g\"])\n",
    "    df[\"Dry_Dead_g\"] = np.maximum(0, df[\"Dry_Total_g\"] - df[\"GDM_g\"])\n",
    "    return df[[\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“˜ æ•°æ®è¯»å–ä¸é¢„å¤„ç†\n",
    "\n",
    "# 1ï¸âƒ£ è¯»å–åŸå§‹æ•°æ®\n",
    "df_file_path = Path(DIRS[\"dir\"] / \"test.csv\")\n",
    "df = pd.read_csv(df_file_path)\n",
    "show_df_info(df, \"test.csv\")\n",
    "\n",
    "# 2ï¸âƒ£ æå–å”¯ä¸€ IDï¼ˆä¾‹å¦‚ \"ID1011485656__Dry_Green_g\" â†’ \"ID1011485656\"ï¼‰\n",
    "df[\"ID\"] = df[\"sample_id\"].str.split(\"__\").str[0]\n",
    "\n",
    "# 3ï¸âƒ£ å°† ID åˆ—ç§»åŠ¨åˆ°æœ€å‰é¢\n",
    "df = move_column_first(df, \"ID\")\n",
    "\n",
    "df[\"target\"] = 0\n",
    "\n",
    "show_df_info(df, \"df\")\n",
    "\n",
    "# ğŸ§© ç›®æ ‡å€¼é€è§†ï¼ˆè¡Œè½¬åˆ—ï¼‰\n",
    "df_targets = (\n",
    "    df\n",
    "    .pivot_table(\n",
    "        index=\"ID\",\n",
    "        columns=\"target_name\",\n",
    "        values=\"target\",\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "df_targets.columns.name = None  # å»æ‰å¤šçº§åˆ—åå±‚æ¬¡\n",
    "show_df_info(df_targets, \"df_targets\")\n",
    "\n",
    "# ğŸ§¬ æå–å…ƒä¿¡æ¯ï¼ˆæ¯ä¸ª ID ä»…ä¿ç•™ä¸€è¡Œï¼‰\n",
    "# meta_cols = [\n",
    "#     \"ID\", \"image_path\", \"Sampling_Date\", \"State\",\n",
    "#     \"Species\", \"Pre_GSHH_NDVI\", \"Height_Ave_cm\"\n",
    "# ]\n",
    "\n",
    "meta_cols = [\n",
    "    \"ID\", \"image_path\"\n",
    "]\n",
    "df_meta = df[meta_cols].drop_duplicates(subset=\"ID\")\n",
    "show_df_info(df_meta, \"df_meta\")\n",
    "\n",
    "# ğŸ”— åˆå¹¶å…ƒä¿¡æ¯ä¸ç›®æ ‡æ•°æ®\n",
    "df_test = pd.merge(df_meta, df_targets, on=\"ID\", how=\"left\")\n",
    "\n",
    "show_df_info(df_test, \"df_wide\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def predict_ensemble_df(df_test, transform, model, model_target_cols, model_dir, device, batch_size=32, img_size=768):\n",
    "\n",
    "    model_dir = model_dir\n",
    "    print(f\"æ¨¡å‹ç›®å½•: {model_dir}\")\n",
    "    assert model_dir.exists(), f\"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}\"\n",
    "\n",
    "    # ğŸ” æœç´¢æ‰€æœ‰ fold æ¨¡å‹\n",
    "    model_paths = sorted(model_dir.glob(\"model_weights_fold*.pt\"))\n",
    "    if not model_paths:\n",
    "        raise FileNotFoundError(f\"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_dir}/model_weights_fold*.pt\")\n",
    "\n",
    "    print(f\"ğŸ”¹ æ£€æµ‹åˆ° {len(model_paths)} ä¸ªæ¨¡å‹:\")\n",
    "    for p in model_paths:\n",
    "        print(\"   -\", p.name)\n",
    "\n",
    "    # 3ï¸âƒ£ æ„å»ºæµ‹è¯•æ•°æ®é›†\n",
    "    test_dataset = DualStreamDataset(\n",
    "        df_test,\n",
    "        image_dir=DIRS[\"dir\"],\n",
    "        target_cols=None,\n",
    "        transform=transform   \n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # å­˜å‚¨æ¯ä¸ªfoldçš„é¢„æµ‹\n",
    "    fold_preds = []\n",
    "\n",
    "    for fold, model_path in enumerate(model_paths):\n",
    "        # print(f\"ğŸš€ åŠ è½½æ¨¡å‹ {fold+1}/{len(model_paths)}: {model_path.name}\")\n",
    "\n",
    "        # 1ï¸âƒ£ åŠ è½½æ¨¡å‹ç»“æ„\n",
    "        model = model\n",
    "\n",
    "        # 2ï¸âƒ£ åŠ è½½æƒé‡\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "\n",
    "        # 3ï¸âƒ£ æ¨ç†\n",
    "        preds_list = []\n",
    "        with torch.no_grad():\n",
    "            for img_left, img_right in test_loader:\n",
    "                img_left, img_right = img_left.to(device, non_blocking=True), img_right.to(device, non_blocking=True)\n",
    "                preds = model(img_left, img_right)\n",
    "                preds_list.append(preds.cpu().numpy())\n",
    "\n",
    "        fold_pred = np.concatenate(preds_list, axis=0)\n",
    "        fold_preds.append(fold_pred)\n",
    "\n",
    "    # 4ï¸âƒ£ å¤šæ¨¡å‹å¹³å‡\n",
    "    preds_mean = np.mean(fold_preds, axis=0)\n",
    "    df_pred3 = pd.DataFrame(preds_mean, columns=model_target_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # æ¢å¤å®Œæ•´çš„ 5 ä¸ªç›®æ ‡åˆ—\n",
    "    df_pred5 = recover_all_targets(df_pred3)\n",
    "    show_df_info(df_pred5, \"df_pred5 \")\n",
    "\n",
    "\n",
    "    # è¿½åŠ æ ·æœ¬ ID å¹¶è°ƒæ•´åˆ—é¡ºåº\n",
    "    df_pred5[\"ID\"] = df_test[\"ID\"]\n",
    "    df_pred5 = df_pred5[[\"ID\"] + target_cols]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # æ‰“å°ç»“æœé¢„è§ˆ\n",
    "    show_df_info(df_pred5, \"final df_pred5\")\n",
    "\n",
    "    return df_pred5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_transforms = {\n",
    "    \"base\": A.Compose([\n",
    "        A.Resize(768, 768),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    \"hflip\": A.Compose([\n",
    "        A.Resize(768, 768),\n",
    "        A.HorizontalFlip(p=1),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    \"vflip\": A.Compose([\n",
    "        A.Resize(768, 768),\n",
    "        A.VerticalFlip(p=1),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ï¸âƒ£ åŠ è½½æ¨¡å‹ç»“æ„\n",
    "model = MyDualStreamModel(\"convnext_tiny\", \n",
    "                          pretrained=False, \n",
    "                          freeze_ratio=config[\"freeze_ratio\"], \n",
    "                          weights_dict=weights)\n",
    "model = model.to(device)\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "\n",
    "model_dir = history_DIR\n",
    "model_dir = history_DIR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tta_preds = []\n",
    "\n",
    "for name, tform in tta_transforms.items():\n",
    "    print(f\"ğŸš€ Running TTA: {name}\")\n",
    "\n",
    "\n",
    "    transform = tform\n",
    "    df_pred5 = predict_ensemble_df(\n",
    "        df_test=df_test,\n",
    "        transform = transform,\n",
    "        model = model,\n",
    "        model_target_cols=model_target_cols,\n",
    "        model_dir = model_dir,\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    print(df_pred5)\n",
    "    tta_preds.append(df_pred5[target_cols].values)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(tta_preds)\n",
    "mean_preds = np.mean(tta_preds, axis=0)\n",
    "\n",
    "print(mean_preds)\n",
    "df_pred_final = df_pred5.copy()\n",
    "df_pred_final[target_cols] = mean_preds\n",
    "print(df_pred_final)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# ğŸ“¤ 5ï¸âƒ£ ç”Ÿæˆ Kaggle æäº¤æ–‡ä»¶ submission.csv\n",
    "# =========================================\n",
    "# æŒ‰æŒ‡å®šé¡ºåºå±•å¼€\n",
    "ordered_target_cols = [\n",
    "    \"Dry_Clover_g\",  # 1ï¸âƒ£\n",
    "    \"Dry_Dead_g\",    # 2ï¸âƒ£\n",
    "    \"Dry_Green_g\",   # 3ï¸âƒ£\n",
    "    \"Dry_Total_g\",   # 4ï¸âƒ£\n",
    "    \"GDM_g\"          # 5ï¸âƒ£\n",
    "]\n",
    "\n",
    "df_submit = (\n",
    "    df_pred5\n",
    "    .melt(id_vars=\"ID\", value_vars=ordered_target_cols,\n",
    "          var_name=\"target_name\", value_name=\"target\")\n",
    ")\n",
    "\n",
    "# ç»„åˆæˆ Kaggle æ‰€éœ€çš„ sample_id\n",
    "df_submit[\"sample_id\"] = df_submit[\"ID\"] + \"__\" + df_submit[\"target_name\"]\n",
    "\n",
    "df_submit = move_column_first(df_submit, \"target\")\n",
    "df_submit = move_column_first(df_submit, \"sample_id\")\n",
    "\n",
    "# åªä¿ç•™ Kaggle è¦çš„ä¸¤åˆ—\n",
    "df_submit = df_submit[[\"sample_id\", \"target\"]]\n",
    "df_submit\n",
    "# æŒ‰ sample_id æ’åºï¼ˆå¯é€‰ï¼‰\n",
    "# df_submit = df_submit.sort_values(\"sample_id\").reset_index(drop=True)\n",
    "\n",
    "# ä¿å­˜æ–‡ä»¶\n",
    "df_submit.to_csv(\"submission.csv\", index=False)\n",
    "print(\"âœ… å·²ç”Ÿæˆæäº¤æ–‡ä»¶ submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 8607422,
     "sourceId": 13552583,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
