{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install optuna pymysql sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5c8e624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 当前状态：实验运行\n",
      "📂 Study Name: test\n"
     ]
    }
   ],
   "source": [
    "ISTEST = True\n",
    "\n",
    "\n",
    "# ISTEST = False\n",
    "\n",
    "STUDY_NAME = \"test\" if ISTEST else \"optuna_task1\"\n",
    "\n",
    "if ISTEST:\n",
    "    status_msg = \"🧪 当前状态：实验运行\"\n",
    "else:\n",
    "    status_msg = \"🚀 当前状态：正式运行\"\n",
    "\n",
    "print(status_msg)\n",
    "print(f\"📂 Study Name: {STUDY_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb05eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avalon available: True\n",
      "✅ 路径已创建：\n",
      "\n",
      "dir          : D:\\数据\\Kaggle\\Thermophysical Property Melting Point\n",
      "DATA_DIR000  : D:\\数据\\Kaggle\\Thermophysical Property Melting Point\\DATA_DIR000\n",
      "HISTORY      : D:\\数据\\Kaggle\\Thermophysical Property Melting Point\\HISTORY\n",
      "SUBMISSION   : D:\\数据\\Kaggle\\Thermophysical Property Melting Point\\SUBMISSION\n"
     ]
    }
   ],
   "source": [
    "# 系统库\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import socket\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 第三方科学计算 & 可视化\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置中文字体，避免乱码\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']        # 黑体\n",
    "plt.rcParams['axes.unicode_minus'] = False          # 解决负号显示成方块的问题\n",
    "\n",
    "# 机器学习 & 优化\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer\n",
    "\n",
    "# 化学信息学 (RDKit)\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import (\n",
    "    Descriptors, Crippen, rdMolDescriptors,\n",
    "    MACCSkeys, RDKFingerprint, rdFingerprintGenerator\n",
    ")\n",
    "from rdkit.Chem.AtomPairs import Pairs, Torsions\n",
    "\n",
    "# 关闭 RDKit 的警告\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# Avalon 指纹（可选）\n",
    "try:\n",
    "    from rdkit.Avalon import pyAvalonTools\n",
    "    avalon_available = True\n",
    "except ImportError:\n",
    "    avalon_available = False\n",
    "print(f\"Avalon available: {avalon_available}\")\n",
    "\n",
    "# Kaggle API\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe_connected\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if socket.gethostname() == 'hao-2':\n",
    "    dir = r'D:\\数据\\Kaggle\\Thermophysical Property Melting Point'\n",
    "else:\n",
    "    dir = os.getcwd()\n",
    "\n",
    "\n",
    "DIRS = {\n",
    "    \"dir\":              dir,                                       \n",
    "    \"DATA_DIR000\":      os.path.join(dir, \"DATA_DIR000\"),\n",
    "    \"HISTORY\":          os.path.join(dir, \"HISTORY\"),\n",
    "    \"SUBMISSION\":       os.path.join(dir, \"SUBMISSION\"),\n",
    "}\n",
    "\n",
    "# 自动创建目录\n",
    "for key, path in DIRS.items():\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# 打印时一行一个地址\n",
    "print(\"✅ 路径已创建：\\n\")\n",
    "for key, path in DIRS.items():\n",
    "    print(f\"{key:<12} : {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc226c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ merge_df 加载完成，shape = (28808, 6530)\n",
      "✅ test_df  加载完成，shape = (666, 6530)\n",
      "特征字段: SMILES, Tm | 描述符: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\n",
      "合计特征总数 = 6528\n"
     ]
    }
   ],
   "source": [
    "# 读取已处理好的最终特征数据\n",
    "\n",
    "# 特征字段: SMILES, Tm | 描述符: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\n",
    "# 合计特征总数 = 6528\n",
    "\n",
    "# 定义路径\n",
    "merge_fp_path = os.path.join(DIRS['DATA_DIR000'], \"merge_fingerprints.csv\")\n",
    "test_fp_path  = os.path.join(DIRS['DATA_DIR000'], \"test_fingerprints.csv\")\n",
    "\n",
    "# 读取数据\n",
    "merge_df = pd.read_csv(merge_fp_path)\n",
    "test_df  = pd.read_csv(test_fp_path)\n",
    "\n",
    "# 打印信息\n",
    "print(f\"✅ merge_df 加载完成，shape = {merge_df.shape}\")\n",
    "print(f\"✅ test_df  加载完成，shape = {test_df.shape}\")\n",
    "\n",
    "print(\"特征字段: SMILES, Tm | 描述符: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\")\n",
    "print(\"合计特征总数 = 6528\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "268ee02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 数据拆分完成\n",
      "训练集特征 features_train  shape   : (500, 20)\n",
      "训练集目标   target_train  shape   : (500,)\n",
      "测试集特征  features_test  shape   : (666, 20)\n",
      "           features_train  类型    : <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 数据拆分 (特征矩阵 与 目标向量)\n",
    "# ============================================\n",
    "# 特征字段: SMILES, Tm | 描述符: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\n",
    "# 合计特征总数 = 6528\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 构建训练集与测试集\n",
    "# # 1. 找到重复的 SMILES\n",
    "# dup_smiles = set(merge_df['SMILES']) & set(test_df['SMILES'])\n",
    "# print(f\"⚠️ 检测到 {len(dup_smiles)} 个重复 SMILES\")\n",
    "\n",
    "# # 2. 删除 merge_df 里 SMILES 在 test_df 里的行\n",
    "# before_shape = merge_df.shape\n",
    "# merge_df = merge_df[~merge_df['SMILES'].isin(test_df['SMILES'])].reset_index(drop=True)\n",
    "# after_shape = merge_df.shape\n",
    "\n",
    "# print(f\"✅ 删除完成: 从 {before_shape} → {after_shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features_train = merge_df.drop(labels=['SMILES', 'Tm'], axis=1)      # 特征矩阵 X：去掉 SMILES 和目标值 Tm\n",
    "target_train = merge_df['Tm']                                      # 目标向量 y：只保留 Tm (熔点，单位 K)\n",
    "features_test = test_df.drop(labels=['SMILES', 'id'], axis=1)  # 测试集特征：去掉 SMILES 和 id (因为 test 没有 Tm)\n",
    "\n",
    "\n",
    "\n",
    "# 随机选取部分特征（示例：50 个）\n",
    "if ISTEST:\n",
    "    np.random.seed(42)\n",
    "    selected_features = np.random.choice(\n",
    "        merge_df.drop(columns=['SMILES', 'Tm']).columns,\n",
    "        size=20,\n",
    "        replace=False\n",
    "    )\n",
    "    sample_len = 500\n",
    "    features_train = merge_df.iloc[:sample_len][selected_features]   # 训练特征 (前 1000 条)\n",
    "    target_train = merge_df.iloc[:sample_len]['Tm']               # 训练目标\n",
    "    features_test = test_df[selected_features]          # 测试特征 (同样的特征列)\n",
    "\n",
    "\n",
    "\n",
    "# 3. 打印维度信息\n",
    "print(\"📊 数据拆分完成\")\n",
    "print(f\"训练集特征 features_train  shape   : {features_train.shape}\")\n",
    "print(f\"训练集目标   target_train  shape   : {target_train.shape}\")\n",
    "print(f\"测试集特征  features_test  shape   : {features_test.shape}\")\n",
    "print(f\"           features_train  类型    : {type(features_train)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4877be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold + XGBoost 进行训练验证，并保存实验结果\n",
    "# ==============================================================\n",
    "def run_kfold_xgb(features_train, target_train, features_test, params, DIRS, K_FOLDS=5, verbose=0):\n",
    "    \"\"\"\n",
    "    使用 Stratified K-Fold + XGBoost 进行训练验证，并保存实验结果\n",
    "\n",
    "    参数:\n",
    "        features_train, target_train        : 训练集特征和标签\n",
    "        features_test      : 测试集特征\n",
    "        params      : XGBoost 最优参数 (dict)\n",
    "        DIRS        : 保存结果的目录字典\n",
    "        K_FOLDS     : 折数 (默认=5)\n",
    "        verbose     : 是否打印详细信息\n",
    "    \"\"\"\n",
    "    # ---------- 创建目录 ----------\n",
    "    for _, path in DIRS.items():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "    time_str = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    history_DIR = os.path.join(DIRS['HISTORY'], time_str)\n",
    "    os.makedirs(history_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"——\" * 20)\n",
    "    print(f\"✅ 当前结果将保存到: {time_str}\")\n",
    "\n",
    "\n",
    "    # ---------- 定义交叉验证 ----------\n",
    "    skfold = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "    yeo = PowerTransformer(method=\"yeo-johnson\")                                # 定义 Yeo-Johnson 变换\n",
    "\n",
    "    # ---------- 初始化存储 ----------\n",
    "    oof_val = np.zeros(len(features_train))       # OOF 预测\n",
    "    train_score, val_score = [], []  # 每折 MAE\n",
    "    test_pred = []                   # 每折 test 预测\n",
    "    fold_records = []                # 保存每折信息\n",
    "    all_importances = []             # 特征重要性\n",
    "    elapsed_list = []                # 耗时记录\n",
    "\n",
    "\n",
    "\n",
    "    # 循环每一折\n",
    "    # ==============================================================\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(skfold.split(features_train, pd.qcut(target_train, q=10).cat.codes), 1):\n",
    "\n",
    "        # ----- 打印时间信息 -----\n",
    "        start_now = datetime.now()\n",
    "        start_str = start_now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "        if elapsed_list:\n",
    "            avg_time = np.mean(elapsed_list)\n",
    "            est_end = start_now + timedelta(seconds=avg_time)\n",
    "\n",
    "            # 每 5 个一组输出耗时\n",
    "            parts = [f\"{t:6.1f}s\" for t in elapsed_list]\n",
    "            grouped = [\" \".join(parts[j:j+5]) for j in range(0, len(parts), 5)]\n",
    "            elapsed_str = \" /// \".join(grouped)\n",
    "\n",
    "            print(\n",
    "                f\"🔄{i:2d}/{K_FOLDS} ST {start_str}\"\n",
    "                f\" ET {est_end.strftime('%H:%M:%S')}\"\n",
    "                f\" avg {avg_time:.1f}s\"\n",
    "                f\" [{elapsed_str}]\",\n",
    "                end=\"\\r\", flush=True\n",
    "            )\n",
    "        else:\n",
    "            print(f\"🔄{i:2d}/{K_FOLDS} ST {start_str} ET (暂无历史数据)\", end=\"\\r\", flush=True)\n",
    "\n",
    "\n",
    "\n",
    "        # ----- 开始训练 -----\n",
    "        t0 = time.time()\n",
    "\n",
    "        # 1. 数据集划分\n",
    "        x_train, x_val = features_train.iloc[train_idx], features_train.iloc[val_idx]\n",
    "        y_train, y_val = target_train[train_idx], target_train[val_idx]\n",
    "\n",
    "        # 2. Yeo-Johnson 变换\n",
    "        y_train = yeo.fit_transform(y_train.values.reshape(-1, 1)).squeeze()\n",
    "        y_val   = yeo.transform(y_val.values.reshape(-1, 1)).squeeze()\n",
    "\n",
    "\n",
    "        # 3. 特征选择（轻量级 XGBoost）\n",
    "        selector_model = xgb.XGBRegressor(\n",
    "            n_estimators=500, \n",
    "            max_depth=6, \n",
    "            learning_rate=0.05,\n",
    "            random_state=42,\n",
    "            device=\"cuda\", \n",
    "            objective=\"reg:absoluteerror\",\n",
    "            tree_method=\"hist\", \n",
    "            verbosity=0\n",
    "        )\n",
    "        selector_model.fit(x_train, y_train)\n",
    "\n",
    "        selector = SelectFromModel(selector_model, prefit=True, threshold=\"mean\")\n",
    "        selected_features = x_train.columns[selector.get_support()].tolist()\n",
    "        if verbose > 0:\n",
    "            print(f\"✅ 选择的特征数量: {len(selected_features)}\")\n",
    "\n",
    "\n",
    "        # 4. 保留重要特征\n",
    "        x_train_new = x_train[selected_features]\n",
    "        x_val_new   = x_val[selected_features]\n",
    "        x_test_new  = features_test[selected_features]\n",
    "\n",
    "        # 5. 转换为 DMatrix\n",
    "        dtrain = xgb.DMatrix(x_train_new, y_train, feature_names=selected_features)\n",
    "        dval   = xgb.DMatrix(x_val_new,   y_val,   feature_names=selected_features)\n",
    "        dtest  = xgb.DMatrix(x_test_new,             feature_names=selected_features)\n",
    "\n",
    "\n",
    "        # 6. XGBoost 训练\n",
    "        xgb_model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=params[\"num_boost_round\"],\n",
    "            evals=[(dtrain, \"train\"), (dval, \"valid\")],\n",
    "            early_stopping_rounds=300,\n",
    "            verbose_eval=(1000 if verbose > 0 else False)\n",
    "        )\n",
    "\n",
    "\n",
    "        # 保存模型\n",
    "        model_path = os.path.join(history_DIR, f\"xgb_model_fold{i}.json\")\n",
    "        xgb_model.save_model(model_path)\n",
    "\n",
    "        # 7. 获取特征重要性\n",
    "        imp_dict = xgb_model.get_score(importance_type=\"gain\")\n",
    "        imp_df = pd.DataFrame(imp_dict.items(), columns=[\"Feature\", \"Importance\"])\n",
    "        imp_df[\"Fold\"] = i\n",
    "        all_importances.append(imp_df)\n",
    "\n",
    "\n",
    "        # 8. 预测\n",
    "        y_train_pred = xgb_model.predict(dtrain)\n",
    "        y_val_pred   = xgb_model.predict(dval)\n",
    "        y_test_pred  = xgb_model.predict(dtest)\n",
    "\n",
    "        # 9. 逆变换\n",
    "        y_train      = yeo.inverse_transform(y_train.reshape(-1, 1)).squeeze()\n",
    "        y_val        = yeo.inverse_transform(y_val.reshape(-1, 1)).squeeze()\n",
    "        y_train_pred = yeo.inverse_transform(y_train_pred.reshape(-1, 1)).squeeze()\n",
    "        y_val_pred   = yeo.inverse_transform(y_val_pred.reshape(-1, 1)).squeeze()\n",
    "        y_test_pred  = yeo.inverse_transform(y_test_pred.reshape(-1, 1)).squeeze()\n",
    "\n",
    "        # 10. 计算 MAE\n",
    "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "        val_mae   = mean_absolute_error(y_val,   y_val_pred)\n",
    "        if verbose > 0:\n",
    "            print(f\"Fold {i}: Train MAE={train_mae:.4f}, Val MAE={val_mae:.4f}，用时 {elapsed:.2f} 秒\")\n",
    "\n",
    "\n",
    "\n",
    "        # ----- 保存结果 -----\n",
    "        train_score.append(train_mae)\n",
    "        val_score.append(val_mae)\n",
    "        oof_val[val_idx] = y_val_pred\n",
    "        test_pred.append(y_test_pred)\n",
    "\n",
    "        elapsed = time.time() - t0\n",
    "        elapsed_list.append(elapsed)\n",
    "\n",
    "        fold_records.append({\n",
    "            \"Fold\": i,\n",
    "            \"Train_MAE\": train_mae,\n",
    "            \"Val_MAE\": val_mae,\n",
    "            \"Num_Features\": len(selected_features),\n",
    "            \"Selected_Features\": selected_features,\n",
    "            \"elapsed\": elapsed\n",
    "        })\n",
    "\n",
    "    # 保存整体结果\n",
    "    # ==============================================================\n",
    "    if verbose > 0:\n",
    "        print(\"\\n\")\n",
    "        print(f\"📊 Train MAE 平均值 : {np.mean(train_score):.4f}\")\n",
    "        print(f\"📊 Val   MAE 平均值 : {np.mean(val_score):.4f}\")\n",
    "        print(f\"📊 Train MAE 标准差 : {np.std(train_score, ddof=0):.4f}\")\n",
    "        print(f\"📊 Val   MAE 标准差 : {np.std(val_score, ddof=0):.4f}\")\n",
    "\n",
    "    # 参数\n",
    "    with open(os.path.join(history_DIR, \"params.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(params, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # 每折信息\n",
    "    folds_df = pd.DataFrame(fold_records)\n",
    "    folds_df.to_csv(os.path.join(history_DIR, \"folds_info.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "    # 特征重要性\n",
    "    if all_importances:\n",
    "        valid_imps = [df for df in all_importances if not df.empty]\n",
    "        all_imp_df = pd.concat(valid_imps, axis=0) if valid_imps else pd.DataFrame(columns=[\"Feature\", \"Importance\", \"Fold\"])\n",
    "    else:\n",
    "        all_imp_df = pd.DataFrame(columns=[\"Feature\", \"Importance\", \"Fold\"])\n",
    "    all_imp_df.to_csv(os.path.join(history_DIR, \"feature_importance_all.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "    # 测试集预测\n",
    "    test_pred_array = np.vstack(test_pred).T\n",
    "    test_pred_df = pd.DataFrame(test_pred_array, columns=[f\"Fold_{j+1}\" for j in range(test_pred_array.shape[1])])\n",
    "    test_pred_df[\"Final_Pred\"] = test_pred_df.mean(axis=1)\n",
    "    test_pred_df.to_csv(os.path.join(history_DIR, \"test_predictions.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 总结\n",
    "    with open(os.path.join(history_DIR, \"summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Train MAE Mean : {np.mean(train_score):.4f}\\n\")\n",
    "        f.write(f\"Val   MAE Mean : {np.mean(val_score):.4f}\\n\")\n",
    "        f.write(f\"Train MAE Std  : {np.std(train_score, ddof=0):.4f}\\n\")\n",
    "        f.write(f\"Val   MAE Std  : {np.std(val_score, ddof=0):.4f}\\n\")\n",
    "\n",
    "\n",
    "    # 最终提交\n",
    "    final_score = np.mean(val_score)\n",
    "    submission = pd.read_csv(os.path.join(DIRS['DATA_DIR000'], \"sample_submission.csv\"))\n",
    "    submission[\"Tm\"] = test_pred_df[\"Final_Pred\"]\n",
    "\n",
    "    submission_path = os.path.join(history_DIR, f\"sub_{time_str}_{final_score:.8f}.csv\")\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    submission.to_csv(os.path.join(DIRS['SUBMISSION'], f\"sub_{time_str}_{final_score:.8f}.csv\"), index=False)\n",
    "\n",
    "\n",
    "    # ---------- 返回结果 ----------\n",
    "    return {\n",
    "        \"oof_val\": oof_val,\n",
    "        \"train_score\": train_score,\n",
    "        \"val_score\": val_score,\n",
    "        \"test_pred\": test_pred_df,\n",
    "        \"folds_info\": folds_df,\n",
    "        \"feature_importance\": all_imp_df,\n",
    "        \"submission_path\": submission_path,\n",
    "        \"time\": time_str,\n",
    "        \"final_score\": final_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93b04208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化任务  加入标识符 host: hao-2   ip: 192.168.40.1\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna 的目标函数 (Objective Function)\n",
    "    每次 trial 会生成一组超参数，用于训练 XGBoost 模型，\n",
    "    并返回交叉验证的平均 RMSE 作为优化目标。\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 定义 XGBoost 超参数搜索空间\n",
    "    xgb_params = {\n",
    "        \"verbosity\"        : 0,                                   # 训练时日志输出级别 (0=静默)\n",
    "        \"objective\"        : \"reg:absoluteerror\",              # 回归任务目标函数\n",
    "        \"tree_method\"      : \"gpu_hist\",                          # 使用 GPU 加速的直方图算法\n",
    "        \"predictor\"        : \"gpu_predictor\",                     # GPU 预测\n",
    "        \"device\"           : \"cuda\",                              # 指定设备 (CUDA GPU)\n",
    "        \"eval_metric\"      : \"mae\",                               # 评估指标：平均绝对误差\n",
    "        \"booster\"          : \"gbtree\",                            # 基学习器：树模型\n",
    "        \"num_boost_round\"     : 20000,                               # 如果用 sklearn API 才保留；xgb.train 用 num_boost_round\n",
    "\n",
    "        # -------- 需要调优的超参数 --------\n",
    "        \"max_depth\"        : trial.suggest_int  (\"max_depth\"       , 3    , 7),\n",
    "        \"learning_rate\"    : trial.suggest_float(\"learning_rate\"   , 0.01 , 0.3 , log=True),\n",
    "        \"min_child_weight\" : trial.suggest_int  (\"min_child_weight\", 1    , 10),\n",
    "        \"subsample\"        : trial.suggest_float(\"subsample\"       , 0.5  , 1.0),\n",
    "        \"colsample_bytree\" : trial.suggest_float(\"colsample_bytree\", 0.5  , 1.0),\n",
    "        \"gamma\"            : trial.suggest_float(\"gamma\"           , 0.0  , 1.0),\n",
    "        \"reg_lambda\"       : trial.suggest_float(\"reg_lambda\"      , 0.1  , 5.0 , log=True),\n",
    "        \"reg_alpha\"        : trial.suggest_float(\"reg_alpha\"       , 0.1  , 1.0 , log=True),\n",
    "    }\n",
    "\n",
    "\n",
    "    results = run_kfold_xgb(features_train, target_train, features_test, xgb_params, DIRS, K_FOLDS = 10, verbose = 0)\n",
    "\n",
    "    score = results['final_score']\n",
    "    \n",
    "\n",
    "    \n",
    "    HOSTNAME = socket.gethostname()\n",
    "    HOST_IP = socket.gethostbyname(HOSTNAME)\n",
    "    trial.set_user_attr(\"host\", HOSTNAME)        # 你自己定义主机 A/B\n",
    "    trial.set_user_attr(\"ip\", HOST_IP)        # 你自己定义角色 A/B\n",
    "\n",
    "    \n",
    "    # 4. 返回平均 MAE\n",
    "    return score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9422187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 15:55:03,256] Using an existing study with name 'test' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主机名: hao-2  主机 IP: 192.168.40.1\n",
      "🔎 开始超参数搜索...\n",
      "————————————————————————————————————————\n",
      "✅ 当前结果将保存到: 2025-10-21 15-55-04\n",
      "🔄10/10 ST 15:55:24 ET 15:55:26 avg 2.2s [   2.0s    2.7s    1.5s    3.4s    1.6s ///    2.0s    2.5s    1.5s    2.8s]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 15:55:26,125] Trial 6 finished with value: 63.064621230468745 and parameters: {'max_depth': 3, 'learning_rate': 0.019651386606002744, 'min_child_weight': 6, 'subsample': 0.5334783686346105, 'colsample_bytree': 0.5894583143905426, 'gamma': 0.49088975643532917, 'reg_lambda': 0.15242062420054192, 'reg_alpha': 0.21577721406330097}. Best is trial 6 with value: 63.064621230468745.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————————————————————————————————\n",
      "✅ 当前结果将保存到: 2025-10-21 15-55-26\n",
      "🔄10/10 ST 15:55:41 ET 15:55:43 avg 1.7s [   1.5s    2.5s    1.4s    1.6s    1.5s ///    1.5s    1.5s    2.2s    1.7s]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 15:55:44,048] Trial 7 finished with value: 63.42987898193358 and parameters: {'max_depth': 3, 'learning_rate': 0.16701877404534557, 'min_child_weight': 8, 'subsample': 0.6649407630812719, 'colsample_bytree': 0.8350044077322408, 'gamma': 0.5935872801065222, 'reg_lambda': 0.15156043255073376, 'reg_alpha': 0.30274397572605766}. Best is trial 6 with value: 63.064621230468745.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————————————————————————————————\n",
      "✅ 当前结果将保存到: 2025-10-21 15-55-44\n",
      "🔄10/10 ST 15:56:04 ET 15:56:06 avg 2.3s [   1.9s    3.3s    1.5s    3.4s    1.5s ///    2.0s    1.7s    1.4s    3.9s]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 15:56:06,540] Trial 8 finished with value: 63.14212542968748 and parameters: {'max_depth': 3, 'learning_rate': 0.013736348754728076, 'min_child_weight': 7, 'subsample': 0.5852735359947805, 'colsample_bytree': 0.68036314460227, 'gamma': 0.7599864574319253, 'reg_lambda': 0.2653823032465253, 'reg_alpha': 0.19019002717897487}. Best is trial 6 with value: 63.064621230468745.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 训练完成！\n",
      "📊 已完成试验次数 : 9\n",
      "🏆 最优试验编号   : 6\n",
      "📉 最优 MAE       : 63.064621230468745\n",
      "⚙️ 最优参数组合   : {'max_depth': 3, 'learning_rate': 0.019651386606002744, 'min_child_weight': 6, 'subsample': 0.5334783686346105, 'colsample_bytree': 0.5894583143905426, 'gamma': 0.49088975643532917, 'reg_lambda': 0.15242062420054192, 'reg_alpha': 0.21577721406330097}\n"
     ]
    }
   ],
   "source": [
    "# 开始优化\n",
    "\n",
    "# 1. 定义 SQLite 数据库存储路径\n",
    "\n",
    "storage_url = \"mysql+pymysql://user1:123456@10.162.147.95:3306/kaggle_melting_point_optuna\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name = STUDY_NAME,\n",
    "    # study_name=\"ghsdjsrtjrswtjhwrt\",\n",
    "    storage=storage_url,\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "# 自动获取当前主机名\\当前主机的 IP 地址\n",
    "HOSTNAME = socket.gethostname()\n",
    "HOST_IP = socket.gethostbyname(HOSTNAME)\n",
    "print(\"主机名:\", HOSTNAME,\" 主机 IP:\", HOST_IP)\n",
    "time.sleep(1)\n",
    "\n",
    "# 5. 启动超参数搜索\n",
    "print(\"🔎 开始超参数搜索...\")\n",
    "if ISTEST:\n",
    "    study.optimize(objective, n_trials = 3)\n",
    "else:\n",
    "    study.optimize(objective, n_trials = 100)\n",
    "\n",
    "\n",
    "# 6. 打印最优结果\n",
    "print(\"\\n✅ 训练完成！\")\n",
    "print(f\"📊 已完成试验次数 : {len(study.trials)}\")\n",
    "print(f\"🏆 最优试验编号   : {study.best_trial.number}\")\n",
    "print(f\"📉 最优 MAE       : {study.best_value}\")\n",
    "print(f\"⚙️ 最优参数组合   : {study.best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eb4503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6becea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "停止运行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e074d107",
   "metadata": {},
   "source": [
    "# 管理数据库信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "258b33c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据库中的 study 列表:\n",
      "- test\n",
      "         Trials:\n",
      "    Trial    0: host=hao-2           , ip=192.168.40.1   , value=63.3390   , params={'max_depth': 7, 'learning_rate': 0.014881350294625223, 'min_child_weight': 6, 'subsample': 0.7434737625708363, 'colsample_bytree': 0.9897332098694307, 'gamma': 0.2774819216237613, 'reg_lambda': 0.5956939885569088, 'reg_alpha': 0.6311524797185967}\n",
      "    Trial    1: host=hao-2           , ip=192.168.40.1   , value=63.6148   , params={'max_depth': 3, 'learning_rate': 0.2713247898317377, 'min_child_weight': 7, 'subsample': 0.9849126281161902, 'colsample_bytree': 0.8309378401166326, 'gamma': 0.7814392281295133, 'reg_lambda': 3.2585889489649014, 'reg_alpha': 0.235425190902393}\n",
      "    Trial    2: host=hao-2           , ip=192.168.40.1   , value=63.3587   , params={'max_depth': 5, 'learning_rate': 0.05739020873816809, 'min_child_weight': 10, 'subsample': 0.6583362500908256, 'colsample_bytree': 0.5101341233098649, 'gamma': 0.6972120855106135, 'reg_lambda': 3.618819426954319, 'reg_alpha': 0.1364431449462794}\n",
      "    Trial    3: host=hao-2           , ip=192.168.40.1   , value=63.1698   , params={'max_depth': 4, 'learning_rate': 0.010684385348500094, 'min_child_weight': 7, 'subsample': 0.677502588848207, 'colsample_bytree': 0.8564329920489518, 'gamma': 0.9007377834132619, 'reg_lambda': 0.29012528778881785, 'reg_alpha': 0.2532545196762364}\n",
      "    Trial    4: host=hao-2           , ip=192.168.40.1   , value=63.2542   , params={'max_depth': 3, 'learning_rate': 0.02415841699596378, 'min_child_weight': 10, 'subsample': 0.8770903924941493, 'colsample_bytree': 0.8827606894431587, 'gamma': 0.730689040965059, 'reg_lambda': 0.11850428241010616, 'reg_alpha': 0.9828137567158434}\n",
      "    Trial    5: host=hao-2           , ip=192.168.40.1   , value=63.6910   , params={'max_depth': 7, 'learning_rate': 0.11417427789523216, 'min_child_weight': 6, 'subsample': 0.9257953313915841, 'colsample_bytree': 0.8881933816423004, 'gamma': 0.12052847243890474, 'reg_lambda': 0.7658902130962354, 'reg_alpha': 0.24079518857358084}\n",
      "    Trial    6: host=hao-2           , ip=192.168.40.1   , value=63.0646   , params={'max_depth': 3, 'learning_rate': 0.019651386606002744, 'min_child_weight': 6, 'subsample': 0.5334783686346105, 'colsample_bytree': 0.5894583143905426, 'gamma': 0.49088975643532917, 'reg_lambda': 0.15242062420054192, 'reg_alpha': 0.21577721406330097}\n",
      "    Trial    7: host=hao-2           , ip=192.168.40.1   , value=63.4299   , params={'max_depth': 3, 'learning_rate': 0.16701877404534557, 'min_child_weight': 8, 'subsample': 0.6649407630812719, 'colsample_bytree': 0.8350044077322408, 'gamma': 0.5935872801065222, 'reg_lambda': 0.15156043255073376, 'reg_alpha': 0.30274397572605766}\n",
      "    Trial    8: host=hao-2           , ip=192.168.40.1   , value=63.1421   , params={'max_depth': 3, 'learning_rate': 0.013736348754728076, 'min_child_weight': 7, 'subsample': 0.5852735359947805, 'colsample_bytree': 0.68036314460227, 'gamma': 0.7599864574319253, 'reg_lambda': 0.2653823032465253, 'reg_alpha': 0.19019002717897487}\n",
      "    总 trial 数量: 9\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 查询数据库详细数据\n",
    "\n",
    "storage_url = \"mysql+pymysql://user1:123456@10.162.147.95:3306/kaggle_melting_point_optuna\"\n",
    "\n",
    "studies = optuna.study.get_all_study_summaries(storage=storage_url)\n",
    "\n",
    "if not studies:\n",
    "    print(\"❌ 当前数据库里无 study\")\n",
    "else:\n",
    "    print(\"✅ 数据库中的 study 列表:\")\n",
    "    for s in studies:\n",
    "\n",
    "        print(\"-\", s.study_name)\n",
    "\n",
    "        study = optuna.load_study(study_name=s.study_name, storage=storage_url)\n",
    "\n",
    "        print(\"         Trials:\")\n",
    "        for trial in study.trials:\n",
    "            host = trial.user_attrs.get(\"host\") or \"unknown\"\n",
    "            ip = trial.user_attrs.get(\"ip\") or \"unknown\"\n",
    "            value = f\"{trial.value:.4f}\" if trial.value is not None else \"None\"\n",
    "\n",
    "            print(\n",
    "                f\"    Trial {trial.number:4d}: \"\n",
    "                f\"host={host:<16}, ip={ip:<15}, \"\n",
    "                f\"value={value:<10}, params={trial.params}\"\n",
    "            )\n",
    "\n",
    "        print(\"    总 trial 数量:\", len(study.trials))\n",
    "        print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cff1ca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "现有 study： ['test']\n",
      "Study:   test                          , Trials:    9\n"
     ]
    }
   ],
   "source": [
    "# 清理前：先查看数据库里当前有哪些 study 存在，以及每个 study 里有多少个 trial\n",
    "\n",
    "storage = \"mysql+pymysql://user1:123456@10.162.147.95:3306/kaggle_melting_point_optuna\"\n",
    "\n",
    "studies = optuna.study.get_all_study_summaries(storage=storage)\n",
    "print(\"现有 study：\", [s.study_name for s in studies])\n",
    "\n",
    "for s in studies:\n",
    "    study = optuna.load_study(study_name=s.study_name, storage=storage)\n",
    "    print(f\"Study:   {s.study_name:30s}, Trials: {len(study.trials):4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c32f73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理中：删除指定 study\n",
    "# 指定要删除的名称\n",
    "to_delete = [\"melting_point_study\"]   # 可以写一个或多个\n",
    "to_delete = []   # 可以写一个或多个\n",
    "\n",
    "for s in studies:\n",
    "    if s.study_name in to_delete:\n",
    "        optuna.delete_study(study_name=s.study_name, storage=storage)\n",
    "        print(\"已删除:\", s.study_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47a5e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清理后 study： ['test']\n"
     ]
    }
   ],
   "source": [
    "# 清理后：再次检查\n",
    "studies_after = optuna.study.get_all_study_summaries(storage=storage)\n",
    "print(\"清理后 study：\", [s.study_name for s in studies_after])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84390793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec45b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "停止运行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1e22ee",
   "metadata": {},
   "source": [
    "# 单次训练推导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49b0c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前最优 MAE : 63.064621230468745 \n",
      "\n",
      "verbosity           : 0                   \n",
      "objective           : reg:absoluteerror   \n",
      "tree_method         : gpu_hist            \n",
      "predictor           : gpu_predictor       \n",
      "device              : cuda                \n",
      "eval_metric         : mae                 \n",
      "booster             : gbtree              \n",
      "num_boost_round     : 20000               \n",
      "max_depth           : 3                   \n",
      "learning_rate       : 0.019651386606002744\n",
      "min_child_weight    : 6                   \n",
      "subsample           : 0.5334783686346105  \n",
      "colsample_bytree    : 0.5894583143905426  \n",
      "gamma               : 0.49088975643532917 \n",
      "reg_lambda          : 0.15242062420054192 \n",
      "reg_alpha           : 0.21577721406330097 \n"
     ]
    }
   ],
   "source": [
    "# 从 Optuna study 获取最优参数\n",
    "\n",
    "storage = \"mysql+pymysql://user1:123456@10.162.147.95:3306/kaggle_melting_point_optuna\"\n",
    "\n",
    "# 只加载指定 study\n",
    "study = optuna.load_study(study_name=STUDY_NAME, storage=storage)\n",
    "\n",
    "print(f\"当前最优 MAE : {study.best_value} \\n\")\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# 构造最终训练用参数（对齐格式）\n",
    "params = {\n",
    "    \"verbosity\"        : 0,                                   # 日志静默\n",
    "    \"objective\"        : \"reg:absoluteerror\",                 # 回归任务目标函数 (MAE)\n",
    "    \"tree_method\"      : \"gpu_hist\",                          # GPU 加速直方图算法\n",
    "    \"predictor\"        : \"gpu_predictor\",                     # GPU 预测\n",
    "    \"device\"           : \"cuda\",                              # CUDA GPU\n",
    "    \"eval_metric\"      : \"mae\",                               # 评估指标\n",
    "    \"booster\"          : \"gbtree\",                            # 树模型\n",
    "    \"num_boost_round\"  : 20_000,                              # 最大迭代次数\n",
    "\n",
    "    # -------- 调优后的超参数 --------\n",
    "    \"max_depth\"        : best_params.get(\"max_depth\"       , 6   ),\n",
    "    \"learning_rate\"    : best_params.get(\"learning_rate\"   , 0.10),\n",
    "    \"min_child_weight\" : best_params.get(\"min_child_weight\", 6   ),\n",
    "    \"subsample\"        : best_params.get(\"subsample\"       , 0.60),\n",
    "    \"colsample_bytree\" : best_params.get(\"colsample_bytree\", 0.60),\n",
    "    \"gamma\"            : best_params.get(\"gamma\"           , 0.40),\n",
    "    \"reg_lambda\"       : best_params.get(\"reg_lambda\"      , 1.60), \n",
    "    \"reg_alpha\"        : best_params.get(\"reg_alpha\"       , 0.40),\n",
    "}\n",
    "\n",
    "\n",
    "for k, v in params.items():\n",
    "    print(f\"{k:20s}: {str(v):20s}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2048049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params.get(\"lambda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a16d3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————————————————————————————————\n",
      "✅ 当前结果将保存到: 2025-10-21 15-58-09\n",
      "🔄10/10 ST 15:58:29 ET 15:58:31 avg 2.2s [   2.1s    2.6s    1.5s    3.5s    1.6s ///    2.1s    2.4s    1.5s    2.8s]\n",
      " 63.064621230468745\n"
     ]
    }
   ],
   "source": [
    "# 单一执行一次\n",
    "\n",
    "results = run_kfold_xgb(features_train, target_train, features_test, params, DIRS, K_FOLDS = 10, verbose = 0)\n",
    "\n",
    "score = results['final_score']\n",
    "\n",
    "print('\\n',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da34bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "停止运行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13bb468",
   "metadata": {},
   "source": [
    "# 提交 kaggle 平台测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af747198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据 submission_time 定位文件路径 提交 kaggle 平台测试\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "\n",
    "def find_submission_file(submission_time, submission_dir):\n",
    "    \"\"\"\n",
    "    在 submission_dir 下查找包含 submission_time 的文件\n",
    "    一旦找到立刻返回完整路径；如果没找到则返回 None\n",
    "    \"\"\"\n",
    "    for fname in os.listdir(submission_dir):\n",
    "        if submission_time in fname:\n",
    "            file_path = os.path.join(submission_dir, fname)\n",
    "            print(f\"✅ 找到目标文件: {fname}\")\n",
    "            return file_path\n",
    "    \n",
    "    print(f\"⚠️ 未找到包含 {submission_time} 的文件\")\n",
    "    return None\n",
    "\n",
    "def submit_and_get_score(file_path, competition_name, message=\"My submission\"):\n",
    "    \"\"\"\n",
    "    封装 Kaggle 提交并等待结果评分\n",
    "    --------------------------------------\n",
    "    file_path        : str  提交文件路径\n",
    "    competition_name : str  Kaggle 比赛名称 (URL 最后一段)\n",
    "    message          : str  提交备注\n",
    "    \"\"\"\n",
    "    # 1. 配置 Kaggle API\n",
    "    os.environ[\"KAGGLE_CONFIG_DIR\"] = r\"C:\\Users\\Admin\\.kaggle\"\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    print(\"✅ Kaggle API 已经配置成功！\")\n",
    "\n",
    "    # 2. 提交文件\n",
    "    api.competition_submit(\n",
    "        file_name=file_path,\n",
    "        competition=competition_name,\n",
    "        message=message\n",
    "    )\n",
    "    print(\"✅ 提交完成！请等待评分...\")\n",
    "\n",
    "    # 3. 动态等待\n",
    "    spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n",
    "    while True:\n",
    "        submissions = api.competition_submissions(competition_name)\n",
    "        latest = submissions[0]\n",
    "        status_str = str(latest._status).lower()\n",
    "\n",
    "        if \"complete\" in status_str and latest._public_score is not None:\n",
    "            print(\"\\n🎯 最终结果:\")\n",
    "            print(f\"Public 分数 : {latest._public_score}\")\n",
    "            print(f\"Private 分数: {latest._private_score}\")\n",
    "            print(f\"提交 ID     : {latest._ref}\")\n",
    "            print(f\"文件名      : {latest._file_name}\")\n",
    "            print(f\"状态        : {latest._status}\")\n",
    "            print(f\"提交时间    : {latest._date}\")\n",
    "            print(f\"描述/备注   : {latest._description}\")\n",
    "            return latest\n",
    "\n",
    "        spin_char = next(spinner)\n",
    "        print(f\"当前状态: {status_str} , 等待中 {spin_char}\", end=\"\\r\", flush=True)\n",
    "        time.sleep(0.2)  # 每 0.5 秒检查一次\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03847a15",
   "metadata": {},
   "source": [
    "### 不轻易运行，再三考虑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a8f4665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 找到目标文件: sub_2025-10-21 15-58-09_63.06462123.csv\n"
     ]
    }
   ],
   "source": [
    "# submission_time 提交\n",
    "submission_time = \"2025-10-21 15-58-09\"   \n",
    "competition_name = \"melting-point\"\n",
    "message =  \"本地提交测试\"\n",
    "\n",
    "target_file = find_submission_file(submission_time, DIRS['SUBMISSION'] )\n",
    "\n",
    "# submit_and_get_score(target_file, competition_name, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "停止运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9b69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd282f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
