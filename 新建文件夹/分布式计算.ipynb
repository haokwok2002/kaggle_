{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958e341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install optuna pymysql sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb05eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\æ–°å»ºæ–‡ä»¶å¤¹\\data\n",
      "DATA_DIR000: c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\æ–°å»ºæ–‡ä»¶å¤¹\\DATA_DIR000\n",
      "âœ… è·¯å¾„å·²åˆ›å»ºï¼š\n",
      "\n",
      "DATA         : c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\æ–°å»ºæ–‡ä»¶å¤¹\\data\n",
      "DATA_DIR000  : c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\æ–°å»ºæ–‡ä»¶å¤¹\\DATA_DIR000\n",
      "OPTUNA       : c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\æ–°å»ºæ–‡ä»¶å¤¹\\data\\optuna\n",
      "HISTORY      : c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\æ–°å»ºæ–‡ä»¶å¤¹\\data\\HISTORY\n",
      "SUBMISSION   : c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\æ–°å»ºæ–‡ä»¶å¤¹\\data\\submission\n"
     ]
    }
   ],
   "source": [
    "# ç³»ç»Ÿåº“\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import socket\n",
    "from datetime import datetime\n",
    "\n",
    "# ç¬¬ä¸‰æ–¹åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer\n",
    "\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "DATA_DIR = cwd + r\"\\data\"\n",
    "DATA_DIR000 = cwd + r\"\\DATA_DIR000\"\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"DATA_DIR000:\", DATA_DIR000)\n",
    "\n",
    "DIRS = {\n",
    "    \"DATA\": DATA_DIR,\n",
    "    \"DATA_DIR000\": DATA_DIR000,\n",
    "    \"OPTUNA\": os.path.join(DATA_DIR, \"optuna\"),\n",
    "    \"HISTORY\": os.path.join(DATA_DIR, \"HISTORY\"),\n",
    "    \"SUBMISSION\": os.path.join(DATA_DIR, \"submission\"),\n",
    "}\n",
    "\n",
    "# è‡ªåŠ¨åˆ›å»ºç›®å½•\n",
    "for key, path in DIRS.items():\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# æ‰“å°æ—¶ä¸€è¡Œä¸€ä¸ªåœ°å€\n",
    "print(\"âœ… è·¯å¾„å·²åˆ›å»ºï¼š\\n\")\n",
    "for key, path in DIRS.items():\n",
    "    print(f\"{key:<12} : {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9160f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "isTEST = False\n",
    "\n",
    "study_name = \"uptuna_task1\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc226c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… merge_df åŠ è½½å®Œæˆï¼Œshape = (28808, 6530)\n",
      "âœ… test_df  åŠ è½½å®Œæˆï¼Œshape = (666, 6530)\n",
      "ç‰¹å¾å­—æ®µ: SMILES, Tm | æè¿°ç¬¦: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\n",
      "åˆè®¡ç‰¹å¾æ€»æ•° = 6528\n"
     ]
    }
   ],
   "source": [
    "# è¯»å–å·²å¤„ç†å¥½çš„æœ€ç»ˆç‰¹å¾æ•°æ®\n",
    "\n",
    "# ç‰¹å¾å­—æ®µ: SMILES, Tm | æè¿°ç¬¦: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\n",
    "# åˆè®¡ç‰¹å¾æ€»æ•° = 6528\n",
    "\n",
    "# å®šä¹‰è·¯å¾„\n",
    "merge_fp_path = os.path.join(DIRS['DATA_DIR000'], \"merge_fingerprints.csv\")\n",
    "test_fp_path  = os.path.join(DIRS['DATA_DIR000'], \"test_fingerprints.csv\")\n",
    "\n",
    "# è¯»å–æ•°æ®\n",
    "merge_df = pd.read_csv(merge_fp_path)\n",
    "test_df  = pd.read_csv(test_fp_path)\n",
    "\n",
    "# æ‰“å°ä¿¡æ¯\n",
    "print(f\"âœ… merge_df åŠ è½½å®Œæˆï¼Œshape = {merge_df.shape}\")\n",
    "print(f\"âœ… test_df  åŠ è½½å®Œæˆï¼Œshape = {test_df.shape}\")\n",
    "\n",
    "print(\"ç‰¹å¾å­—æ®µ: SMILES, Tm | æè¿°ç¬¦: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\")\n",
    "print(\"åˆè®¡ç‰¹å¾æ€»æ•° = 6528\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "268ee02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š æ•°æ®æ‹†åˆ†å®Œæˆ\n",
      "è®­ç»ƒé›†ç‰¹å¾ x        shape   : (28808, 6528)\n",
      "è®­ç»ƒé›†ç›®æ ‡ y        shape   : (28808,)\n",
      "æµ‹è¯•é›†ç‰¹å¾ X_test   shape   : (666, 6528)\n",
      "x ç±»å‹: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# æ•°æ®æ‹†åˆ† (è®­ç»ƒé›†ä¸æµ‹è¯•é›†)\n",
    "# ============================================\n",
    "# ç‰¹å¾å­—æ®µ: SMILES, Tm | æè¿°ç¬¦: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\n",
    "# åˆè®¡ç‰¹å¾æ€»æ•° = 6528\n",
    "\n",
    "\n",
    "# # æ„å»ºè®­ç»ƒé›†ä¸æµ‹è¯•é›†\n",
    "# # 1. æ‰¾åˆ°é‡å¤çš„ SMILES\n",
    "# dup_smiles = set(merge_df['SMILES']) & set(test_df['SMILES'])\n",
    "# print(f\"âš ï¸ æ£€æµ‹åˆ° {len(dup_smiles)} ä¸ªé‡å¤ SMILES\")\n",
    "\n",
    "# # 2. åˆ é™¤ merge_df é‡Œ SMILES åœ¨ test_df é‡Œçš„è¡Œ\n",
    "# before_shape = merge_df.shape\n",
    "# merge_df = merge_df[~merge_df['SMILES'].isin(test_df['SMILES'])].reset_index(drop=True)\n",
    "# after_shape = merge_df.shape\n",
    "\n",
    "# print(f\"âœ… åˆ é™¤å®Œæˆ: ä» {before_shape} â†’ {after_shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = merge_df.drop(labels=['SMILES', 'Tm'], axis=1)      # ç‰¹å¾çŸ©é˜µ Xï¼šå»æ‰ SMILES å’Œç›®æ ‡å€¼ Tm\n",
    "y = merge_df['Tm']                                      # ç›®æ ‡å‘é‡ yï¼šåªä¿ç•™ Tm (ç†”ç‚¹ï¼Œå•ä½ K)\n",
    "x_test = test_df.drop(labels=['SMILES', 'id'], axis=1)  # æµ‹è¯•é›†ç‰¹å¾ï¼šå»æ‰ SMILES å’Œ id (å› ä¸º test æ²¡æœ‰ Tm)\n",
    "\n",
    "\n",
    "# éšæœºé€‰å–éƒ¨åˆ†ç‰¹å¾ï¼ˆç¤ºä¾‹ï¼š50 ä¸ªï¼‰\n",
    "if isTEST:\n",
    "    np.random.seed(42)\n",
    "    selected_features = np.random.choice(\n",
    "        merge_df.drop(columns=['SMILES', 'Tm']).columns,\n",
    "        size=5,\n",
    "        replace=False\n",
    "    )\n",
    "    sample_len = 500\n",
    "    x = merge_df.iloc[:sample_len][selected_features]   # è®­ç»ƒç‰¹å¾ (å‰ 1000 æ¡)\n",
    "    y = merge_df.iloc[:sample_len]['Tm']               # è®­ç»ƒç›®æ ‡\n",
    "    x_test = test_df[selected_features]          # æµ‹è¯•ç‰¹å¾ (åŒæ ·çš„ç‰¹å¾åˆ—)\n",
    "\n",
    "\n",
    "\n",
    "# 3. æ‰“å°ç»´åº¦ä¿¡æ¯\n",
    "print(\"ğŸ“Š æ•°æ®æ‹†åˆ†å®Œæˆ\")\n",
    "print(f\"è®­ç»ƒé›†ç‰¹å¾ x        shape   : {x.shape}\")\n",
    "print(f\"è®­ç»ƒé›†ç›®æ ‡ y        shape   : {y.shape}\")\n",
    "print(f\"æµ‹è¯•é›†ç‰¹å¾ X_test   shape   : {x_test.shape}\")\n",
    "print(f\"x ç±»å‹: {type(x)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4877be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold + XGBoost è¿›è¡Œè®­ç»ƒéªŒè¯ï¼Œå¹¶ä¿å­˜å®éªŒç»“æœ\n",
    "def run_kfold_xgb(x, y, x_test, params, DIRS, K_FOLDS=5, verbose=0):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ Stratified K-Fold + XGBoost è¿›è¡Œè®­ç»ƒéªŒè¯ï¼Œå¹¶ä¿å­˜å®éªŒç»“æœ\n",
    "\n",
    "    å‚æ•°:\n",
    "        x, y        : è®­ç»ƒé›†ç‰¹å¾å’Œæ ‡ç­¾\n",
    "        x_test      : æµ‹è¯•é›†ç‰¹å¾\n",
    "        params : XGBoost æœ€ä¼˜å‚æ•° (dict)\n",
    "        ITEM_DIR    : ä¿å­˜ç»“æœçš„æ ¹ç›®å½•\n",
    "        K_FOLDS     : æŠ˜æ•° (é»˜è®¤=5)\n",
    "        random_state: éšæœºç§å­\n",
    "    \"\"\"\n",
    "    # è‡ªåŠ¨åˆ›å»ºç›®å½•\n",
    "    for key, path in DIRS.items():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # ä½¿ç”¨ Stratified K-Fold + XGBoost è¿›è¡Œè®­ç»ƒéªŒè¯\n",
    "\n",
    "    time_str = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    history_DIR = os.path.join(DIRS['HISTORY'], time_str)\n",
    "    os.makedirs(history_DIR, exist_ok=True)\n",
    "    print(f\"âœ… ç»“æœå°†ä¿å­˜åˆ°: {time_str}\")\n",
    "\n",
    "\n",
    "\n",
    "    # å®šä¹‰åˆ†å±‚ K æŠ˜äº¤å‰éªŒè¯\n",
    "    # K_FOLDS = 5\n",
    "    skfold = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    # å®šä¹‰ Yeo-Johnson å˜æ¢\n",
    "    yeo = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "    # åˆå§‹åŒ–å­˜å‚¨å˜é‡\n",
    "    oof_val = np.zeros(len(x))       # OOF é¢„æµ‹\n",
    "    train_score, val_score = [], []  # æ¯æŠ˜ MAE\n",
    "    test_pred = []                   # æ¯æŠ˜ test é¢„æµ‹\n",
    "    fold_records = []                # ä¿å­˜æ¯æŠ˜ä¿¡æ¯\n",
    "    all_importances = []\n",
    "\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skfold.split(x, pd.qcut(y, q=10).cat.codes), 1):\n",
    "        print(f\"ğŸ”„ Fold {i}/{K_FOLDS} å¼€å§‹...\", end=\"\\r\", flush=True)\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print(f\"ğŸ”„ Fold {i}/{K_FOLDS} å¼€å§‹...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 1. æ•°æ®é›†åˆ’åˆ†\n",
    "        x_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        # 2. ç›®æ ‡å€¼ Yeo-Johnson å˜æ¢\n",
    "        y_train = yeo.fit_transform(y_train.values.reshape(-1, 1)).squeeze()\n",
    "        y_val   = yeo.transform(y_val.values.reshape(-1, 1)).squeeze()\n",
    "\n",
    "        # 3. ç‰¹å¾é€‰æ‹©ï¼ˆè½»é‡çº§ XGBoost æ¨¡å‹ï¼‰\n",
    "        selector_model = xgb.XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            random_state=42,\n",
    "            device='cuda',\n",
    "            objective=\"reg:absoluteerror\",\n",
    "            tree_method='hist',\n",
    "            verbosity=0\n",
    "        )\n",
    "        selector_model.fit(x_train, y_train)\n",
    "\n",
    "        # ä½¿ç”¨ SelectFromModel ä¿ç•™é‡è¦ç‰¹å¾\n",
    "        selector = SelectFromModel(selector_model, prefit=True, threshold=\"mean\")\n",
    "        selected_idx = selector.get_support(indices=True)\n",
    "        selected_features = x_train.columns[selected_idx].tolist()\n",
    "        if verbose > 0:\n",
    "            print(f\"âœ… é€‰æ‹©çš„ç‰¹å¾æ•°é‡: {len(selected_features)}\")\n",
    "\n",
    "        # 4. ä¿ç•™é‡è¦ç‰¹å¾\n",
    "        x_train_new = x_train[selected_features]\n",
    "        x_val_new   = x_val[selected_features]\n",
    "        x_test_new  = x_test[selected_features]\n",
    "\n",
    "        # 5. è½¬æ¢ä¸º DMatrix\n",
    "        dtrain = xgb.DMatrix(x_train_new, y_train, feature_names=selected_features)\n",
    "        dval   = xgb.DMatrix(x_val_new, y_val, feature_names=selected_features)\n",
    "        dtest  = xgb.DMatrix(x_test_new, feature_names=selected_features)\n",
    "\n",
    "        # 6. XGBoost è®­ç»ƒ\n",
    "        xgb_model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=params[\"num_boost_round\"],\n",
    "            evals=[(dtrain, 'train'), (dval, 'valid')],\n",
    "            early_stopping_rounds=300,\n",
    "            verbose_eval=(1000 if verbose > 0 else False)\n",
    "        )\n",
    "        # # è¾“å‡ºæ¨¡å‹é…ç½®\n",
    "        # config = json.loads(xgb_model.save_config())\n",
    "        # print(json.dumps(config, indent=4))\n",
    "\n",
    "        # ä¿å­˜æ¨¡å‹\n",
    "        model_path = os.path.join(history_DIR, f\"xgb_model_fold{i}.json\")\n",
    "        xgb_model.save_model(model_path)\n",
    "        if verbose > 0:\n",
    "            print(f\"âœ… Fold {i} çš„æ¨¡å‹å·²ä¿å­˜åˆ° {model_path}\")\n",
    "\n",
    "\n",
    "\n",
    "        # 7. è·å–ç‰¹å¾é‡è¦æ€§ï¼ˆæŒ‰ gainï¼‰\n",
    "        importance_dict = xgb_model.get_score(importance_type='gain')\n",
    "        importance_df = pd.DataFrame(importance_dict.items(), columns=['Feature', 'Importance'])\n",
    "        importance_df[\"Fold\"] = i\n",
    "        all_importances.append(importance_df)\n",
    "\n",
    "        # 8. é¢„æµ‹\n",
    "        y_train_pred = xgb_model.predict(dtrain)\n",
    "        y_val_pred   = xgb_model.predict(dval)\n",
    "        y_test_pred  = xgb_model.predict(dtest)\n",
    "\n",
    "        # 9. é€†å˜æ¢\n",
    "        y_train = yeo.inverse_transform(y_train.reshape(-1, 1)).squeeze()\n",
    "        y_val   = yeo.inverse_transform(y_val.reshape(-1, 1)).squeeze()\n",
    "        y_train_pred = yeo.inverse_transform(y_train_pred.reshape(-1, 1)).squeeze()\n",
    "        y_val_pred   = yeo.inverse_transform(y_val_pred.reshape(-1, 1)).squeeze()\n",
    "        y_test_pred  = yeo.inverse_transform(y_test_pred.reshape(-1, 1)).squeeze()\n",
    "\n",
    "        # 10. è®¡ç®— MAE\n",
    "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "        val_mae   = mean_absolute_error(y_val, y_val_pred)\n",
    "        elapsed = time.time() - start_time\n",
    "        if verbose > 0:\n",
    "            print(f\"Fold {i} : Train MAE = {train_mae:.4f}, Val MAE = {val_mae:.4f}ï¼Œç”¨æ—¶ {elapsed:.2f} ç§’\")\n",
    "\n",
    "        # ä¿å­˜ç»“æœ\n",
    "        train_score.append(train_mae)\n",
    "        val_score.append(val_mae)\n",
    "        oof_val[val_index] = y_val_pred\n",
    "        test_pred.append(y_test_pred)\n",
    "\n",
    "        # ä¿å­˜æ¯æŠ˜ä¿¡æ¯\n",
    "        fold_records.append({\n",
    "            \"Fold\": i,\n",
    "            \"Train_MAE\": train_mae,\n",
    "            \"Val_MAE\": val_mae,\n",
    "            \"Num_Features\": len(selected_features),\n",
    "            \"Selected_Features\": selected_features,\n",
    "            \"elapsed\": elapsed\n",
    "        })\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "    # æ‰“å°æ•´ä½“ç»“æœ\n",
    "    if verbose > 0:\n",
    "            print(f\"\\nğŸ“Š Train MAE å¹³å‡å€¼ : {np.mean(train_score):.4f}\")\n",
    "            print(f\"ğŸ“Š Val   MAE å¹³å‡å€¼ : {np.mean(val_score):.4f}\")\n",
    "            print(f\"ğŸ“Š Train MAE æ ‡å‡†å·® : {np.std(train_score, ddof=0):.4f}\")\n",
    "            print(f\"ğŸ“Š Val   MAE æ ‡å‡†å·® : {np.std(val_score, ddof=0):.4f}\")\n",
    "\n",
    "\n",
    "    # ä¿å­˜å‚æ•°\n",
    "    with open(os.path.join(history_DIR, \"params.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(params, f, indent=4, ensure_ascii=False)\n",
    "    if verbose > 0: print(f\"âœ… å½“å‰å‚æ•°å·²ä¿å­˜\")\n",
    "\n",
    "    # ä¿å­˜æ¯æŠ˜ä¿¡æ¯\n",
    "    folds_df = pd.DataFrame(fold_records)\n",
    "    folds_df.to_csv(os.path.join(history_DIR, \"folds_info.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "    if verbose > 0: print(f\"âœ… æ¯æŠ˜ä¿¡æ¯å·²ä¿å­˜\")\n",
    "\n",
    "    # ä¿å­˜é‡è¦æ€§\n",
    "    all_importances_df = pd.concat(\n",
    "        [df for df in all_importances if not df.empty],\n",
    "        axis=0\n",
    "    )\n",
    "    all_importances_df.to_csv(os.path.join(history_DIR, \"feature_importance_all.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # ä¿å­˜é¢„æµ‹\n",
    "    test_pred_array = np.vstack(test_pred).T\n",
    "    test_pred_df = pd.DataFrame(test_pred_array, columns=[f\"Fold_{i+1}\" for i in range(test_pred_array.shape[1])])\n",
    "    test_pred_df[\"Final_Pred\"] = test_pred_df.mean(axis=1)\n",
    "    test_pred_df.to_csv(os.path.join(history_DIR, \"test_predictions.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "    if verbose > 0: print(f\"âœ… æµ‹è¯•é›†é¢„æµ‹ç»“æœå·²ä¿å­˜\")\n",
    "\n",
    "    # ä¿å­˜æ€»ç»“\n",
    "    with open(os.path.join(history_DIR, \"summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Train MAE Mean : {np.mean(train_score):.4f}\\n\")\n",
    "        f.write(f\"Val   MAE Mean : {np.mean(val_score):.4f}\\n\")\n",
    "        f.write(f\"Train MAE Std  : {np.std(train_score, ddof=0):.4f}\\n\")\n",
    "        f.write(f\"Val   MAE Std  : {np.std(val_score, ddof=0):.4f}\\n\")\n",
    "    if verbose > 0: print(f\"âœ… å®éªŒæ€»ç»“å·²ä¿å­˜\")\n",
    "\n",
    "    # æœ€ç»ˆå¾—åˆ†\n",
    "    final_score = np.mean(val_score)\n",
    "\n",
    "\n",
    "    # ä¿å­˜æœ€ç»ˆæäº¤æ–‡ä»¶\n",
    "    submission = pd.read_csv(os.path.join(DIRS['DATA_DIR000'], \"sample_submission.csv\"))\n",
    "    submission[\"Tm\"] = test_pred_df[\"Final_Pred\"]\n",
    "    submission_path = os.path.join(history_DIR, f\"sample_submission_{time_str}_{final_score:.4f}.csv\")\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    submission.to_csv(os.path.join(DIRS['SUBMISSION'], f\"sample_submission_{time_str} {final_score:.4f}.csv\"), index=False)\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"oof_val\": oof_val,\n",
    "        \"train_score\": train_score,\n",
    "        \"val_score\": val_score,\n",
    "        \"test_pred\": test_pred_df,\n",
    "        \"folds_info\": folds_df,\n",
    "        \"feature_importance\": all_importances_df,\n",
    "        \"submission_path\": submission_path,\n",
    "        \"time\": time_str,\n",
    "        \"final_score\": final_score\n",
    "        \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93b04208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ä¼˜åŒ–ä»»åŠ¡  åŠ å…¥æ ‡è¯†ç¬¦ host: hao-2   ip: 192.168.40.1\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna çš„ç›®æ ‡å‡½æ•° (Objective Function)\n",
    "    æ¯æ¬¡ trial ä¼šç”Ÿæˆä¸€ç»„è¶…å‚æ•°ï¼Œç”¨äºè®­ç»ƒ XGBoost æ¨¡å‹ï¼Œ\n",
    "    å¹¶è¿”å›äº¤å‰éªŒè¯çš„å¹³å‡ RMSE ä½œä¸ºä¼˜åŒ–ç›®æ ‡ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. å®šä¹‰ XGBoost è¶…å‚æ•°æœç´¢ç©ºé—´\n",
    "    xgb_params = {\n",
    "        \"verbosity\"        : 0,                                   # è®­ç»ƒæ—¶æ—¥å¿—è¾“å‡ºçº§åˆ« (0=é™é»˜)\n",
    "        \"objective\"        : \"reg:absoluteerror\",              # å›å½’ä»»åŠ¡ç›®æ ‡å‡½æ•°\n",
    "        \"tree_method\"      : \"gpu_hist\",                          # ä½¿ç”¨ GPU åŠ é€Ÿçš„ç›´æ–¹å›¾ç®—æ³•\n",
    "        \"predictor\"        : \"gpu_predictor\",                     # GPU é¢„æµ‹\n",
    "        \"device\"           : \"cuda\",                              # æŒ‡å®šè®¾å¤‡ (CUDA GPU)\n",
    "        \"eval_metric\"      : \"mae\",                               # è¯„ä¼°æŒ‡æ ‡ï¼šå¹³å‡ç»å¯¹è¯¯å·®\n",
    "        \"booster\"          : \"gbtree\",                            # åŸºå­¦ä¹ å™¨ï¼šæ ‘æ¨¡å‹\n",
    "        \"num_boost_round\"     : 20000,                               # å¦‚æœç”¨ sklearn API æ‰ä¿ç•™ï¼›xgb.train ç”¨ num_boost_round\n",
    "\n",
    "        # -------- éœ€è¦è°ƒä¼˜çš„è¶…å‚æ•° --------\n",
    "        \"max_depth\"        : trial.suggest_int  (\"max_depth\"       , 3    , 7),\n",
    "        \"learning_rate\"    : trial.suggest_float(\"learning_rate\"   , 0.01 , 0.3 , log=True),\n",
    "        \"min_child_weight\" : trial.suggest_int  (\"min_child_weight\", 1    , 10),\n",
    "        \"subsample\"        : trial.suggest_float(\"subsample\"       , 0.5  , 1.0),\n",
    "        \"colsample_bytree\" : trial.suggest_float(\"colsample_bytree\", 0.5  , 1.0),\n",
    "        \"gamma\"            : trial.suggest_float(\"gamma\"           , 0.0  , 1.0),\n",
    "        \"reg_lambda\"       : trial.suggest_float(\"reg_lambda\"      , 0.1  , 5.0 , log=True),\n",
    "        \"reg_alpha\"        : trial.suggest_float(\"reg_alpha\"       , 0.1  , 1.0 , log=True),\n",
    "    }\n",
    "\n",
    "\n",
    "    results = run_kfold_xgb(x, y, x_test, xgb_params, DIRS, K_FOLDS = 10, verbose = 0)\n",
    "\n",
    "    score = results['final_score']\n",
    "    \n",
    "\n",
    "    \n",
    "    HOSTNAME = socket.gethostname()\n",
    "    HOST_IP = socket.gethostbyname(HOSTNAME)\n",
    "    trial.set_user_attr(\"host\", HOSTNAME)        # ä½ è‡ªå·±å®šä¹‰ä¸»æœº A/B\n",
    "    trial.set_user_attr(\"ip\", HOST_IP)        # ä½ è‡ªå·±å®šä¹‰è§’è‰² A/B\n",
    "\n",
    "    \n",
    "    # 4. è¿”å›å¹³å‡ MAE\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341a9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9422187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-20 19:13:44,079] A new study created in RDB with name: uptuna_task1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸»æœºå: hao-2  ä¸»æœº IP: 192.168.40.1\n",
      "ğŸ” å¼€å§‹è¶…å‚æ•°æœç´¢...\n",
      "âœ… ç»“æœå°†ä¿å­˜åˆ°: 2025-10-20 19-13-45\n",
      "ğŸ”„ Fold 10/10 å¼€å§‹...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-20 19:48:45,118] Trial 0 finished with value: 20.433422970047086 and parameters: {'max_depth': 5, 'learning_rate': 0.17206098291812266, 'min_child_weight': 2, 'subsample': 0.7375152948804222, 'colsample_bytree': 0.6527074514132962, 'gamma': 0.13296926679566312, 'reg_lambda': 0.25945178381572087, 'reg_alpha': 0.21866799911159526}. Best is trial 0 with value: 20.433422970047086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç»“æœå°†ä¿å­˜åˆ°: 2025-10-20 19-48-45\n",
      "ğŸ”„ Fold 10/10 å¼€å§‹...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-20 20:42:13,044] Trial 3 finished with value: 21.12115505242908 and parameters: {'max_depth': 5, 'learning_rate': 0.21965507400666878, 'min_child_weight': 7, 'subsample': 0.988869163346432, 'colsample_bytree': 0.9236978741221038, 'gamma': 0.02225460451574568, 'reg_lambda': 1.1290924013778356, 'reg_alpha': 0.30290470554405474}. Best is trial 0 with value: 20.433422970047086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç»“æœå°†ä¿å­˜åˆ°: 2025-10-20 20-42-13\n",
      "ğŸ”„ Fold 10/10 å¼€å§‹...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-20 21:48:54,384] Trial 5 finished with value: 18.71585278415173 and parameters: {'max_depth': 7, 'learning_rate': 0.1236547233161385, 'min_child_weight': 6, 'subsample': 0.603611484103293, 'colsample_bytree': 0.6622168252268413, 'gamma': 0.4345349140194519, 'reg_lambda': 1.6747308536449876, 'reg_alpha': 0.44444379592940303}. Best is trial 5 with value: 18.71585278415173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç»“æœå°†ä¿å­˜åˆ°: 2025-10-20 21-48-54\n",
      "ğŸ”„ Fold 10/10 å¼€å§‹...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-20 22:54:57,768] Trial 7 finished with value: 22.860363617966698 and parameters: {'max_depth': 4, 'learning_rate': 0.013054090097980706, 'min_child_weight': 10, 'subsample': 0.8587484032429609, 'colsample_bytree': 0.8868521037299011, 'gamma': 0.5331606838423458, 'reg_lambda': 0.3333284671239319, 'reg_alpha': 0.6927705582982043}. Best is trial 5 with value: 18.71585278415173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç»“æœå°†ä¿å­˜åˆ°: 2025-10-20 22-54-57\n",
      "ğŸ”„ Fold 2/10 å¼€å§‹...\r"
     ]
    }
   ],
   "source": [
    "# å¼€å§‹ä¼˜åŒ–\n",
    "\n",
    "# 1. å®šä¹‰ SQLite æ•°æ®åº“å­˜å‚¨è·¯å¾„\n",
    "\n",
    "storage_url = \"mysql+pymysql://user1:123456@10.162.147.95:3306/kaggle_melting_point_optuna\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name = study_name,\n",
    "    # study_name=\"ghsdjsrtjrswtjhwrt\",\n",
    "    storage=storage_url,\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "# è‡ªåŠ¨è·å–å½“å‰ä¸»æœºå\\å½“å‰ä¸»æœºçš„ IP åœ°å€\n",
    "HOSTNAME = socket.gethostname()\n",
    "HOST_IP = socket.gethostbyname(HOSTNAME)\n",
    "print(\"ä¸»æœºå:\", HOSTNAME,\" ä¸»æœº IP:\", HOST_IP)\n",
    "time.sleep(1)\n",
    "\n",
    "# 5. å¯åŠ¨è¶…å‚æ•°æœç´¢\n",
    "print(\"ğŸ” å¼€å§‹è¶…å‚æ•°æœç´¢...\")\n",
    "if isTEST:\n",
    "    study.optimize(objective, n_trials = 3)\n",
    "else:\n",
    "    study.optimize(objective, n_trials = 100)\n",
    "\n",
    "\n",
    "# 6. æ‰“å°æœ€ä¼˜ç»“æœ\n",
    "print(\"\\nâœ… è®­ç»ƒå®Œæˆï¼\")\n",
    "print(f\"ğŸ“Š å·²å®Œæˆè¯•éªŒæ¬¡æ•° : {len(study.trials)}\")\n",
    "print(f\"ğŸ† æœ€ä¼˜è¯•éªŒç¼–å·   : {study.best_trial.number}\")\n",
    "print(f\"ğŸ“‰ æœ€ä¼˜ MAE       : {study.best_value}\")\n",
    "print(f\"âš™ï¸ æœ€ä¼˜å‚æ•°ç»„åˆ   : {study.best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e074d107",
   "metadata": {},
   "source": [
    "# ç®¡ç†æ•°æ®åº“ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b33c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ å½“å‰æ•°æ®åº“é‡Œæ—  study\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥è¯¢æ•°æ®åº“è¯¦ç»†æ•°æ®\n",
    "\n",
    "storage_url = \"mysql+pymysql://user1:123456@10.162.147.95:3306/kaggle_melting_point_optuna\"\n",
    "\n",
    "studies = optuna.study.get_all_study_summaries(storage=storage_url)\n",
    "\n",
    "if not studies:\n",
    "    print(\"âŒ å½“å‰æ•°æ®åº“é‡Œæ—  study\")\n",
    "else:\n",
    "    print(\"âœ… æ•°æ®åº“ä¸­çš„ study åˆ—è¡¨:\")\n",
    "    for s in studies:\n",
    "\n",
    "        print(\"-\", s.study_name)\n",
    "\n",
    "        study = optuna.load_study(study_name=s.study_name, storage=storage_url)\n",
    "\n",
    "        print(\"         Trials:\")\n",
    "        for trial in study.trials:\n",
    "            host = trial.user_attrs.get(\"host\") or \"unknown\"\n",
    "            ip = trial.user_attrs.get(\"ip\") or \"unknown\"\n",
    "            value = f\"{trial.value:.4f}\" if trial.value is not None else \"None\"\n",
    "\n",
    "            print(\n",
    "                f\"    Trial {trial.number:4d}: \"\n",
    "                f\"host={host:<16}, ip={ip:<15}, \"\n",
    "                f\"value={value}, params={trial.params}\"\n",
    "            )\n",
    "\n",
    "        print(\"    æ€» trial æ•°é‡:\", len(study.trials))\n",
    "        print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1ca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç°æœ‰ studyï¼š []\n"
     ]
    }
   ],
   "source": [
    "# æ¸…ç†å‰ï¼šå…ˆæŸ¥çœ‹æ•°æ®åº“é‡Œå½“å‰æœ‰å“ªäº› study å­˜åœ¨ï¼Œä»¥åŠæ¯ä¸ª study é‡Œæœ‰å¤šå°‘ä¸ª trial\n",
    "\n",
    "storage = \"mysql+pymysql://user1:123456@10.162.147.95:3306/kaggle_melting_point_optuna\"\n",
    "\n",
    "studies = optuna.study.get_all_study_summaries(storage=storage)\n",
    "print(\"ç°æœ‰ studyï¼š\", [s.study_name for s in studies])\n",
    "\n",
    "for s in studies:\n",
    "    study = optuna.load_study(study_name=s.study_name, storage=storage)\n",
    "    print(f\"Study:   {s.study_name:30s}, Trials: {len(study.trials):4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸…ç†ä¸­ï¼šåˆ é™¤æŒ‡å®š study\n",
    "# æŒ‡å®šè¦åˆ é™¤çš„åç§°\n",
    "to_delete = [\"melting_point_study\"]   # å¯ä»¥å†™ä¸€ä¸ªæˆ–å¤šä¸ª\n",
    "to_delete = []   # å¯ä»¥å†™ä¸€ä¸ªæˆ–å¤šä¸ª\n",
    "\n",
    "for s in studies:\n",
    "    if s.study_name in to_delete:\n",
    "        optuna.delete_study(study_name=s.study_name, storage=storage)\n",
    "        print(\"å·²åˆ é™¤:\", s.study_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¸…ç†å studyï¼š []\n"
     ]
    }
   ],
   "source": [
    "# æ¸…ç†åï¼šå†æ¬¡æ£€æŸ¥\n",
    "studies_after = optuna.study.get_all_study_summaries(storage=storage)\n",
    "print(\"æ¸…ç†å studyï¼š\", [s.study_name for s in studies_after])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
