{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958e341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install optuna pymysql sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb05eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\新建文件夹\\data\n",
      "DATA_DIR000: c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\新建文件夹\\DATA_DIR000\n",
      "✅ 路径已创建：\n",
      "\n",
      "DATA         : c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\新建文件夹\\data\n",
      "DATA_DIR000  : c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\新建文件夹\\DATA_DIR000\n",
      "OPTUNA       : c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\新建文件夹\\data\\optuna\n",
      "HISTORY      : c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\新建文件夹\\data\\HISTORY\n",
      "SUBMISSION   : c:\\Users\\Admin\\Documents\\GitHub\\kaggle\\新建文件夹\\data\\submission\n"
     ]
    }
   ],
   "source": [
    "# 系统库\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import socket\n",
    "from datetime import datetime\n",
    "\n",
    "# 第三方库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer\n",
    "\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "DATA_DIR = cwd + r\"\\data\"\n",
    "DATA_DIR000 = cwd + r\"\\DATA_DIR000\"\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"DATA_DIR000:\", DATA_DIR000)\n",
    "\n",
    "DIRS = {\n",
    "    \"DATA\": DATA_DIR,\n",
    "    \"DATA_DIR000\": DATA_DIR000,\n",
    "    \"OPTUNA\": os.path.join(DATA_DIR, \"optuna\"),\n",
    "    \"HISTORY\": os.path.join(DATA_DIR, \"HISTORY\"),\n",
    "    \"SUBMISSION\": os.path.join(DATA_DIR, \"submission\"),\n",
    "}\n",
    "\n",
    "# 自动创建目录\n",
    "for key, path in DIRS.items():\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# 打印时一行一个地址\n",
    "print(\"✅ 路径已创建：\\n\")\n",
    "for key, path in DIRS.items():\n",
    "    print(f\"{key:<12} : {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9160f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "isTEST = False\n",
    "\n",
    "study_name = \"uptuna_task1\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc226c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ merge_df 加载完成，shape = (28808, 6530)\n",
      "✅ test_df  加载完成，shape = (666, 6530)\n",
      "特征字段: SMILES, Tm | 描述符: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\n",
      "合计特征总数 = 6528\n"
     ]
    }
   ],
   "source": [
    "# 读取已处理好的最终特征数据\n",
    "\n",
    "# 特征字段: SMILES, Tm | 描述符: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\n",
    "# 合计特征总数 = 6528\n",
    "\n",
    "# 定义路径\n",
    "merge_fp_path = os.path.join(DIRS['DATA_DIR000'], \"merge_fingerprints.csv\")\n",
    "test_fp_path  = os.path.join(DIRS['DATA_DIR000'], \"test_fingerprints.csv\")\n",
    "\n",
    "# 读取数据\n",
    "merge_df = pd.read_csv(merge_fp_path)\n",
    "test_df  = pd.read_csv(test_fp_path)\n",
    "\n",
    "# 打印信息\n",
    "print(f\"✅ merge_df 加载完成，shape = {merge_df.shape}\")\n",
    "print(f\"✅ test_df  加载完成，shape = {test_df.shape}\")\n",
    "\n",
    "print(\"特征字段: SMILES, Tm | 描述符: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\")\n",
    "print(\"合计特征总数 = 6528\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "268ee02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 数据拆分完成\n",
      "训练集特征 x        shape   : (28808, 6528)\n",
      "训练集目标 y        shape   : (28808,)\n",
      "测试集特征 X_test   shape   : (666, 6528)\n",
      "x 类型: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 数据拆分 (训练集与测试集)\n",
    "# ============================================\n",
    "# 特征字段: SMILES, Tm | 描述符: 217 | Morgan: 1024 | FCFP: 1024 | MACCS: 167 | AtomPair: 1024 | RDKit: 2048 | Avalon: 1024\n",
    "# 合计特征总数 = 6528\n",
    "\n",
    "\n",
    "# # 构建训练集与测试集\n",
    "# # 1. 找到重复的 SMILES\n",
    "# dup_smiles = set(merge_df['SMILES']) & set(test_df['SMILES'])\n",
    "# print(f\"⚠️ 检测到 {len(dup_smiles)} 个重复 SMILES\")\n",
    "\n",
    "# # 2. 删除 merge_df 里 SMILES 在 test_df 里的行\n",
    "# before_shape = merge_df.shape\n",
    "# merge_df = merge_df[~merge_df['SMILES'].isin(test_df['SMILES'])].reset_index(drop=True)\n",
    "# after_shape = merge_df.shape\n",
    "\n",
    "# print(f\"✅ 删除完成: 从 {before_shape} → {after_shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = merge_df.drop(labels=['SMILES', 'Tm'], axis=1)      # 特征矩阵 X：去掉 SMILES 和目标值 Tm\n",
    "y = merge_df['Tm']                                      # 目标向量 y：只保留 Tm (熔点，单位 K)\n",
    "x_test = test_df.drop(labels=['SMILES', 'id'], axis=1)  # 测试集特征：去掉 SMILES 和 id (因为 test 没有 Tm)\n",
    "\n",
    "\n",
    "# 随机选取部分特征（示例：50 个）\n",
    "if isTEST:\n",
    "    np.random.seed(42)\n",
    "    selected_features = np.random.choice(\n",
    "        merge_df.drop(columns=['SMILES', 'Tm']).columns,\n",
    "        size=5,\n",
    "        replace=False\n",
    "    )\n",
    "    sample_len = 500\n",
    "    x = merge_df.iloc[:sample_len][selected_features]   # 训练特征 (前 1000 条)\n",
    "    y = merge_df.iloc[:sample_len]['Tm']               # 训练目标\n",
    "    x_test = test_df[selected_features]          # 测试特征 (同样的特征列)\n",
    "\n",
    "\n",
    "\n",
    "# 3. 打印维度信息\n",
    "print(\"📊 数据拆分完成\")\n",
    "print(f\"训练集特征 x        shape   : {x.shape}\")\n",
    "print(f\"训练集目标 y        shape   : {y.shape}\")\n",
    "print(f\"测试集特征 X_test   shape   : {x_test.shape}\")\n",
    "print(f\"x 类型: {type(x)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4877be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold + XGBoost 进行训练验证，并保存实验结果\n",
    "def run_kfold_xgb(x, y, x_test, params, DIRS, K_FOLDS=5, verbose=0):\n",
    "    \"\"\"\n",
    "    使用 Stratified K-Fold + XGBoost 进行训练验证，并保存实验结果\n",
    "\n",
    "    参数:\n",
    "        x, y        : 训练集特征和标签\n",
    "        x_test      : 测试集特征\n",
    "        params : XGBoost 最优参数 (dict)\n",
    "        ITEM_DIR    : 保存结果的根目录\n",
    "        K_FOLDS     : 折数 (默认=5)\n",
    "        random_state: 随机种子\n",
    "    \"\"\"\n",
    "    # 自动创建目录\n",
    "    for key, path in DIRS.items():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # 使用 Stratified K-Fold + XGBoost 进行训练验证\n",
    "\n",
    "    time_str = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    history_DIR = os.path.join(DIRS['HISTORY'], time_str)\n",
    "    os.makedirs(history_DIR, exist_ok=True)\n",
    "    print(f\"✅ 结果将保存到: {time_str}\")\n",
    "\n",
    "\n",
    "\n",
    "    # 定义分层 K 折交叉验证\n",
    "    # K_FOLDS = 5\n",
    "    skfold = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    # 定义 Yeo-Johnson 变换\n",
    "    yeo = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "    # 初始化存储变量\n",
    "    oof_val = np.zeros(len(x))       # OOF 预测\n",
    "    train_score, val_score = [], []  # 每折 MAE\n",
    "    test_pred = []                   # 每折 test 预测\n",
    "    fold_records = []                # 保存每折信息\n",
    "    all_importances = []\n",
    "\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skfold.split(x, pd.qcut(y, q=10).cat.codes), 1):\n",
    "        print(f\"🔄 Fold {i}/{K_FOLDS} 开始...\", end=\"\\r\", flush=True)\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print(f\"🔄 Fold {i}/{K_FOLDS} 开始...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 1. 数据集划分\n",
    "        x_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        # 2. 目标值 Yeo-Johnson 变换\n",
    "        y_train = yeo.fit_transform(y_train.values.reshape(-1, 1)).squeeze()\n",
    "        y_val   = yeo.transform(y_val.values.reshape(-1, 1)).squeeze()\n",
    "\n",
    "        # 3. 特征选择（轻量级 XGBoost 模型）\n",
    "        selector_model = xgb.XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            random_state=42,\n",
    "            device='cuda',\n",
    "            objective=\"reg:absoluteerror\",\n",
    "            tree_method='hist',\n",
    "            verbosity=0\n",
    "        )\n",
    "        selector_model.fit(x_train, y_train)\n",
    "\n",
    "        # 使用 SelectFromModel 保留重要特征\n",
    "        selector = SelectFromModel(selector_model, prefit=True, threshold=\"mean\")\n",
    "        selected_idx = selector.get_support(indices=True)\n",
    "        selected_features = x_train.columns[selected_idx].tolist()\n",
    "        if verbose > 0:\n",
    "            print(f\"✅ 选择的特征数量: {len(selected_features)}\")\n",
    "\n",
    "        # 4. 保留重要特征\n",
    "        x_train_new = x_train[selected_features]\n",
    "        x_val_new   = x_val[selected_features]\n",
    "        x_test_new  = x_test[selected_features]\n",
    "\n",
    "        # 5. 转换为 DMatrix\n",
    "        dtrain = xgb.DMatrix(x_train_new, y_train, feature_names=selected_features)\n",
    "        dval   = xgb.DMatrix(x_val_new, y_val, feature_names=selected_features)\n",
    "        dtest  = xgb.DMatrix(x_test_new, feature_names=selected_features)\n",
    "\n",
    "        # 6. XGBoost 训练\n",
    "        xgb_model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=params[\"num_boost_round\"],\n",
    "            evals=[(dtrain, 'train'), (dval, 'valid')],\n",
    "            early_stopping_rounds=300,\n",
    "            verbose_eval=(1000 if verbose > 0 else False)\n",
    "        )\n",
    "        # # 输出模型配置\n",
    "        # config = json.loads(xgb_model.save_config())\n",
    "        # print(json.dumps(config, indent=4))\n",
    "\n",
    "        # 保存模型\n",
    "        model_path = os.path.join(history_DIR, f\"xgb_model_fold{i}.json\")\n",
    "        xgb_model.save_model(model_path)\n",
    "        if verbose > 0:\n",
    "            print(f\"✅ Fold {i} 的模型已保存到 {model_path}\")\n",
    "\n",
    "\n",
    "\n",
    "        # 7. 获取特征重要性（按 gain）\n",
    "        importance_dict = xgb_model.get_score(importance_type='gain')\n",
    "        importance_df = pd.DataFrame(importance_dict.items(), columns=['Feature', 'Importance'])\n",
    "        importance_df[\"Fold\"] = i\n",
    "        all_importances.append(importance_df)\n",
    "\n",
    "        # 8. 预测\n",
    "        y_train_pred = xgb_model.predict(dtrain)\n",
    "        y_val_pred   = xgb_model.predict(dval)\n",
    "        y_test_pred  = xgb_model.predict(dtest)\n",
    "\n",
    "        # 9. 逆变换\n",
    "        y_train = yeo.inverse_transform(y_train.reshape(-1, 1)).squeeze()\n",
    "        y_val   = yeo.inverse_transform(y_val.reshape(-1, 1)).squeeze()\n",
    "        y_train_pred = yeo.inverse_transform(y_train_pred.reshape(-1, 1)).squeeze()\n",
    "        y_val_pred   = yeo.inverse_transform(y_val_pred.reshape(-1, 1)).squeeze()\n",
    "        y_test_pred  = yeo.inverse_transform(y_test_pred.reshape(-1, 1)).squeeze()\n",
    "\n",
    "        # 10. 计算 MAE\n",
    "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "        val_mae   = mean_absolute_error(y_val, y_val_pred)\n",
    "        elapsed = time.time() - start_time\n",
    "        if verbose > 0:\n",
    "            print(f\"Fold {i} : Train MAE = {train_mae:.4f}, Val MAE = {val_mae:.4f}，用时 {elapsed:.2f} 秒\")\n",
    "\n",
    "        # 保存结果\n",
    "        train_score.append(train_mae)\n",
    "        val_score.append(val_mae)\n",
    "        oof_val[val_index] = y_val_pred\n",
    "        test_pred.append(y_test_pred)\n",
    "\n",
    "        # 保存每折信息\n",
    "        fold_records.append({\n",
    "            \"Fold\": i,\n",
    "            \"Train_MAE\": train_mae,\n",
    "            \"Val_MAE\": val_mae,\n",
    "            \"Num_Features\": len(selected_features),\n",
    "            \"Selected_Features\": selected_features,\n",
    "            \"elapsed\": elapsed\n",
    "        })\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "    # 打印整体结果\n",
    "    if verbose > 0:\n",
    "            print(f\"\\n📊 Train MAE 平均值 : {np.mean(train_score):.4f}\")\n",
    "            print(f\"📊 Val   MAE 平均值 : {np.mean(val_score):.4f}\")\n",
    "            print(f\"📊 Train MAE 标准差 : {np.std(train_score, ddof=0):.4f}\")\n",
    "            print(f\"📊 Val   MAE 标准差 : {np.std(val_score, ddof=0):.4f}\")\n",
    "\n",
    "\n",
    "    # 保存参数\n",
    "    with open(os.path.join(history_DIR, \"params.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(params, f, indent=4, ensure_ascii=False)\n",
    "    if verbose > 0: print(f\"✅ 当前参数已保存\")\n",
    "\n",
    "    # 保存每折信息\n",
    "    folds_df = pd.DataFrame(fold_records)\n",
    "    folds_df.to_csv(os.path.join(history_DIR, \"folds_info.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "    if verbose > 0: print(f\"✅ 每折信息已保存\")\n",
    "\n",
    "    # 保存重要性\n",
    "    all_importances_df = pd.concat(\n",
    "        [df for df in all_importances if not df.empty],\n",
    "        axis=0\n",
    "    )\n",
    "    all_importances_df.to_csv(os.path.join(history_DIR, \"feature_importance_all.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 保存预测\n",
    "    test_pred_array = np.vstack(test_pred).T\n",
    "    test_pred_df = pd.DataFrame(test_pred_array, columns=[f\"Fold_{i+1}\" for i in range(test_pred_array.shape[1])])\n",
    "    test_pred_df[\"Final_Pred\"] = test_pred_df.mean(axis=1)\n",
    "    test_pred_df.to_csv(os.path.join(history_DIR, \"test_predictions.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "    if verbose > 0: print(f\"✅ 测试集预测结果已保存\")\n",
    "\n",
    "    # 保存总结\n",
    "    with open(os.path.join(history_DIR, \"summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Train MAE Mean : {np.mean(train_score):.4f}\\n\")\n",
    "        f.write(f\"Val   MAE Mean : {np.mean(val_score):.4f}\\n\")\n",
    "        f.write(f\"Train MAE Std  : {np.std(train_score, ddof=0):.4f}\\n\")\n",
    "        f.write(f\"Val   MAE Std  : {np.std(val_score, ddof=0):.4f}\\n\")\n",
    "    if verbose > 0: print(f\"✅ 实验总结已保存\")\n",
    "\n",
    "    # 最终得分\n",
    "    final_score = np.mean(val_score)\n",
    "\n",
    "\n",
    "    # 保存最终提交文件\n",
    "    submission = pd.read_csv(os.path.join(DIRS['DATA_DIR000'], \"sample_submission.csv\"))\n",
    "    submission[\"Tm\"] = test_pred_df[\"Final_Pred\"]\n",
    "    submission_path = os.path.join(history_DIR, f\"sample_submission_{time_str}_{final_score:.4f}.csv\")\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    submission.to_csv(os.path.join(DIRS['SUBMISSION'], f\"sample_submission_{time_str} {final_score:.4f}.csv\"), index=False)\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"oof_val\": oof_val,\n",
    "        \"train_score\": train_score,\n",
    "        \"val_score\": val_score,\n",
    "        \"test_pred\": test_pred_df,\n",
    "        \"folds_info\": folds_df,\n",
    "        \"feature_importance\": all_importances_df,\n",
    "        \"submission_path\": submission_path,\n",
    "        \"time\": time_str,\n",
    "        \"final_score\": final_score\n",
    "        \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93b04208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化任务  加入标识符 host: hao-2   ip: 192.168.40.1\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna 的目标函数 (Objective Function)\n",
    "    每次 trial 会生成一组超参数，用于训练 XGBoost 模型，\n",
    "    并返回交叉验证的平均 RMSE 作为优化目标。\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 定义 XGBoost 超参数搜索空间\n",
    "    xgb_params = {\n",
    "        \"verbosity\"        : 0,                                   # 训练时日志输出级别 (0=静默)\n",
    "        \"objective\"        : \"reg:absoluteerror\",              # 回归任务目标函数\n",
    "        \"tree_method\"      : \"gpu_hist\",                          # 使用 GPU 加速的直方图算法\n",
    "        \"predictor\"        : \"gpu_predictor\",                     # GPU 预测\n",
    "        \"device\"           : \"cuda\",                              # 指定设备 (CUDA GPU)\n",
    "        \"eval_metric\"      : \"mae\",                               # 评估指标：平均绝对误差\n",
    "        \"booster\"          : \"gbtree\",                            # 基学习器：树模型\n",
    "        \"num_boost_round\"     : 20000,                               # 如果用 sklearn API 才保留；xgb.train 用 num_boost_round\n",
    "\n",
    "        # -------- 需要调优的超参数 --------\n",
    "        \"max_depth\"        : trial.suggest_int  (\"max_depth\"       , 3    , 7),\n",
    "        \"learning_rate\"    : trial.suggest_float(\"learning_rate\"   , 0.01 , 0.3 , log=True),\n",
    "        \"min_child_weight\" : trial.suggest_int  (\"min_child_weight\", 1    , 10),\n",
    "        \"subsample\"        : trial.suggest_float(\"subsample\"       , 0.5  , 1.0),\n",
    "        \"colsample_bytree\" : trial.suggest_float(\"colsample_bytree\", 0.5  , 1.0),\n",
    "        \"gamma\"            : trial.suggest_float(\"gamma\"           , 0.0  , 1.0),\n",
    "        \"reg_lambda\"       : trial.suggest_float(\"reg_lambda\"      , 0.1  , 5.0 , log=True),\n",
    "        \"reg_alpha\"        : trial.suggest_float(\"reg_alpha\"       , 0.1  , 1.0 , log=True),\n",
    "    }\n",
    "\n",
    "\n",
    "    results = run_kfold_xgb(x, y, x_test, xgb_params, DIRS, K_FOLDS = 10, verbose = 0)\n",
    "\n",
    "    score = results['final_score']\n",
    "    \n",
    "\n",
    "    \n",
    "    HOSTNAME = socket.gethostname()\n",
    "    HOST_IP = socket.gethostbyname(HOSTNAME)\n",
    "    trial.set_user_attr(\"host\", HOSTNAME)        # 你自己定义主机 A/B\n",
    "    trial.set_user_attr(\"ip\", HOST_IP)        # 你自己定义角色 A/B\n",
    "\n",
    "    \n",
    "    # 4. 返回平均 MAE\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341a9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9422187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-20 19:13:44,079] A new study created in RDB with name: uptuna_task1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主机名: hao-2  主机 IP: 192.168.40.1\n",
      "🔎 开始超参数搜索...\n",
      "✅ 结果将保存到: 2025-10-20 19-13-45\n",
      "🔄 Fold 10/10 开始...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-20 19:48:45,118] Trial 0 finished with value: 20.433422970047086 and parameters: {'max_depth': 5, 'learning_rate': 0.17206098291812266, 'min_child_weight': 2, 'subsample': 0.7375152948804222, 'colsample_bytree': 0.6527074514132962, 'gamma': 0.13296926679566312, 'reg_lambda': 0.25945178381572087, 'reg_alpha': 0.21866799911159526}. Best is trial 0 with value: 20.433422970047086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 结果将保存到: 2025-10-20 19-48-45\n",
      "🔄 Fold 10/10 开始...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-20 20:42:13,044] Trial 3 finished with value: 21.12115505242908 and parameters: {'max_depth': 5, 'learning_rate': 0.21965507400666878, 'min_child_weight': 7, 'subsample': 0.988869163346432, 'colsample_bytree': 0.9236978741221038, 'gamma': 0.02225460451574568, 'reg_lambda': 1.1290924013778356, 'reg_alpha': 0.30290470554405474}. Best is trial 0 with value: 20.433422970047086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 结果将保存到: 2025-10-20 20-42-13\n",
      "🔄 Fold 10/10 开始...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-20 21:48:54,384] Trial 5 finished with value: 18.71585278415173 and parameters: {'max_depth': 7, 'learning_rate': 0.1236547233161385, 'min_child_weight': 6, 'subsample': 0.603611484103293, 'colsample_bytree': 0.6622168252268413, 'gamma': 0.4345349140194519, 'reg_lambda': 1.6747308536449876, 'reg_alpha': 0.44444379592940303}. Best is trial 5 with value: 18.71585278415173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 结果将保存到: 2025-10-20 21-48-54\n",
      "🔄 Fold 10/10 开始...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-20 22:54:57,768] Trial 7 finished with value: 22.860363617966698 and parameters: {'max_depth': 4, 'learning_rate': 0.013054090097980706, 'min_child_weight': 10, 'subsample': 0.8587484032429609, 'colsample_bytree': 0.8868521037299011, 'gamma': 0.5331606838423458, 'reg_lambda': 0.3333284671239319, 'reg_alpha': 0.6927705582982043}. Best is trial 5 with value: 18.71585278415173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 结果将保存到: 2025-10-20 22-54-57\n",
      "🔄 Fold 2/10 开始...\r"
     ]
    }
   ],
   "source": [
    "# 开始优化\n",
    "\n",
    "# 1. 定义 SQLite 数据库存储路径\n",
    "\n",
    "storage_url = \"mysql+pymysql://user1:123456@10.162.147.95:3306/kaggle_melting_point_optuna\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name = study_name,\n",
    "    # study_name=\"ghsdjsrtjrswtjhwrt\",\n",
    "    storage=storage_url,\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "# 自动获取当前主机名\\当前主机的 IP 地址\n",
    "HOSTNAME = socket.gethostname()\n",
    "HOST_IP = socket.gethostbyname(HOSTNAME)\n",
    "print(\"主机名:\", HOSTNAME,\" 主机 IP:\", HOST_IP)\n",
    "time.sleep(1)\n",
    "\n",
    "# 5. 启动超参数搜索\n",
    "print(\"🔎 开始超参数搜索...\")\n",
    "if isTEST:\n",
    "    study.optimize(objective, n_trials = 3)\n",
    "else:\n",
    "    study.optimize(objective, n_trials = 100)\n",
    "\n",
    "\n",
    "# 6. 打印最优结果\n",
    "print(\"\\n✅ 训练完成！\")\n",
    "print(f\"📊 已完成试验次数 : {len(study.trials)}\")\n",
    "print(f\"🏆 最优试验编号   : {study.best_trial.number}\")\n",
    "print(f\"📉 最优 MAE       : {study.best_value}\")\n",
    "print(f\"⚙️ 最优参数组合   : {study.best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e074d107",
   "metadata": {},
   "source": [
    "# 管理数据库信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b33c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 当前数据库里无 study\n"
     ]
    }
   ],
   "source": [
    "# 查询数据库详细数据\n",
    "\n",
    "storage_url = \"mysql+pymysql://user1:123456@10.162.147.95:3306/kaggle_melting_point_optuna\"\n",
    "\n",
    "studies = optuna.study.get_all_study_summaries(storage=storage_url)\n",
    "\n",
    "if not studies:\n",
    "    print(\"❌ 当前数据库里无 study\")\n",
    "else:\n",
    "    print(\"✅ 数据库中的 study 列表:\")\n",
    "    for s in studies:\n",
    "\n",
    "        print(\"-\", s.study_name)\n",
    "\n",
    "        study = optuna.load_study(study_name=s.study_name, storage=storage_url)\n",
    "\n",
    "        print(\"         Trials:\")\n",
    "        for trial in study.trials:\n",
    "            host = trial.user_attrs.get(\"host\") or \"unknown\"\n",
    "            ip = trial.user_attrs.get(\"ip\") or \"unknown\"\n",
    "            value = f\"{trial.value:.4f}\" if trial.value is not None else \"None\"\n",
    "\n",
    "            print(\n",
    "                f\"    Trial {trial.number:4d}: \"\n",
    "                f\"host={host:<16}, ip={ip:<15}, \"\n",
    "                f\"value={value}, params={trial.params}\"\n",
    "            )\n",
    "\n",
    "        print(\"    总 trial 数量:\", len(study.trials))\n",
    "        print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1ca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "现有 study： []\n"
     ]
    }
   ],
   "source": [
    "# 清理前：先查看数据库里当前有哪些 study 存在，以及每个 study 里有多少个 trial\n",
    "\n",
    "storage = \"mysql+pymysql://user1:123456@10.162.147.95:3306/kaggle_melting_point_optuna\"\n",
    "\n",
    "studies = optuna.study.get_all_study_summaries(storage=storage)\n",
    "print(\"现有 study：\", [s.study_name for s in studies])\n",
    "\n",
    "for s in studies:\n",
    "    study = optuna.load_study(study_name=s.study_name, storage=storage)\n",
    "    print(f\"Study:   {s.study_name:30s}, Trials: {len(study.trials):4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理中：删除指定 study\n",
    "# 指定要删除的名称\n",
    "to_delete = [\"melting_point_study\"]   # 可以写一个或多个\n",
    "to_delete = []   # 可以写一个或多个\n",
    "\n",
    "for s in studies:\n",
    "    if s.study_name in to_delete:\n",
    "        optuna.delete_study(study_name=s.study_name, storage=storage)\n",
    "        print(\"已删除:\", s.study_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清理后 study： []\n"
     ]
    }
   ],
   "source": [
    "# 清理后：再次检查\n",
    "studies_after = optuna.study.get_all_study_summaries(storage=storage)\n",
    "print(\"清理后 study：\", [s.study_name for s in studies_after])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
